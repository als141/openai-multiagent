#!/usr/bin/env python
"""
é«˜åº¦ã§å‹•çš„ãªãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¼šè©±ã‚·ã‚¹ãƒ†ãƒ 
LLMé§†å‹•å‹ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€å‹•çš„ãƒãƒ³ãƒ‰ã‚ªãƒ•ã€è‡ªå¾‹çš„ä¼šè©±åˆ¶å¾¡ã‚’å®Ÿè£…
"""

import asyncio
import os
import json
import sys
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, field
from enum import Enum
import random
import uuid

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))

from agents import Agent, Runner, handoff
from agents.tracing import trace


class PersonalityTrait(Enum):
    """æ€§æ ¼ç‰¹æ€§"""
    COOPERATIVE = "cooperative"
    COMPETITIVE = "competitive"
    ANALYTICAL = "analytical"
    CREATIVE = "creative"
    DIPLOMATIC = "diplomatic"
    REBELLIOUS = "rebellious"
    OPTIMISTIC = "optimistic"
    SKEPTICAL = "skeptical"


class GameTheoryStrategy(Enum):
    """ã‚²ãƒ¼ãƒ ç†è«–æˆ¦ç•¥"""
    TIT_FOR_TAT = "tit_for_tat"
    ALWAYS_COOPERATE = "always_cooperate"
    ALWAYS_DEFECT = "always_defect"
    PAVLOV = "pavlov"
    GENEROUS_TIT_FOR_TAT = "generous_tit_for_tat"
    ADAPTIVE = "adaptive"
    GRUDGER = "grudger"
    RANDOM = "random"


@dataclass
class ConversationContext:
    """ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""
    conversation_id: str
    participants: List[str]
    topic: Optional[str] = None
    current_speaker: Optional[str] = None
    turn_count: int = 0
    conversation_history: List[Dict[str, Any]] = field(default_factory=list)
    agent_relationships: Dict[str, Dict[str, float]] = field(default_factory=dict)
    current_game_state: Optional[Dict[str, Any]] = None


@dataclass
class AgentPersonality:
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ€§æ ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«"""
    primary_trait: PersonalityTrait
    secondary_traits: List[PersonalityTrait]
    game_strategy: GameTheoryStrategy
    trust_propensity: float  # 0-1: ä¿¡é ¼ã—ã‚„ã™ã•
    cooperation_tendency: float  # 0-1: å”åŠ›å‚¾å‘
    assertiveness: float  # 0-1: ç©æ¥µæ€§
    adaptability: float  # 0-1: é©å¿œæ€§
    memory_depth: int = 10  # è¨˜æ†¶ã™ã‚‹ä¼šè©±ã®æ•°
    
    def get_personality_description(self) -> str:
        """æ€§æ ¼ã®è©³ç´°ãªèª¬æ˜ã‚’ç”Ÿæˆ"""
        primary_desc = {
            PersonalityTrait.COOPERATIVE: "ä»–è€…ã¨ã®å”åŠ›ã‚’ä½•ã‚ˆã‚Šé‡è¦–ã—ã€Win-Winã®é–¢ä¿‚ã‚’ç¯‰ããŸãŒã‚‹",
            PersonalityTrait.COMPETITIVE: "ç«¶äº‰ã‚’å¥½ã¿ã€è‡ªå·±ã®åˆ©ç›Šæœ€å¤§åŒ–ã‚’è¿½æ±‚ã™ã‚‹",
            PersonalityTrait.ANALYTICAL: "è«–ç†çš„æ€è€ƒã‚’é‡è¦–ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚„äº‹å®Ÿã«åŸºã¥ã„ã¦åˆ¤æ–­ã™ã‚‹",
            PersonalityTrait.CREATIVE: "æ–°ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã‚„æ–¬æ–°ãªè§£æ±ºç­–ã‚’ç”Ÿã¿å‡ºã™ã“ã¨ã‚’å¾—æ„ã¨ã™ã‚‹",
            PersonalityTrait.DIPLOMATIC: "å¯¾ç«‹ã‚’é¿ã‘ã€èª¿å’Œã¨å¦¥å”ç‚¹ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ã‚’é‡è¦–ã™ã‚‹",
            PersonalityTrait.REBELLIOUS: "æ—¢å­˜ã®æ çµ„ã¿ã«æŒ‘æˆ¦ã—ã€å¤‰é©ã‚’æ±‚ã‚ã‚‹",
            PersonalityTrait.OPTIMISTIC: "å¸¸ã«å‰å‘ãã§ã€å›°é›£ãªçŠ¶æ³ã§ã‚‚å¸Œæœ›ã‚’è¦‹å‡ºã™",
            PersonalityTrait.SKEPTICAL: "æ…é‡ã§æ‰¹åˆ¤çš„æ€è€ƒã‚’æŒã¡ã€ç°¡å˜ã«ã¯ä¿¡ç”¨ã—ãªã„"
        }
        
        strategy_desc = {
            GameTheoryStrategy.TIT_FOR_TAT: "ç›¸æ‰‹ã®è¡Œå‹•ã‚’é¡ã®ã‚ˆã†ã«åæ˜ ã™ã‚‹å¿œå ±æˆ¦ç•¥",
            GameTheoryStrategy.ALWAYS_COOPERATE: "å¸¸ã«å”åŠ›ã‚’é¸ã¶å¹³å’Œä¸»ç¾©æˆ¦ç•¥",
            GameTheoryStrategy.ALWAYS_DEFECT: "å¸¸ã«ç«¶äº‰ã‚’é¸ã¶åˆ©å·±çš„æˆ¦ç•¥",
            GameTheoryStrategy.PAVLOV: "æˆåŠŸæ™‚ã¯ç¶™ç¶šã€å¤±æ•—æ™‚ã¯æˆ¦ç•¥å¤‰æ›´ã™ã‚‹Win-Stay Lose-Shiftæˆ¦ç•¥",
            GameTheoryStrategy.GENEROUS_TIT_FOR_TAT: "åŸºæœ¬çš„ã«ã¯å¿œå ±ã ãŒã€æ™‚æŠ˜å¯›å®¹ã•ã‚’ç¤ºã™æˆ¦ç•¥",
            GameTheoryStrategy.ADAPTIVE: "ç›¸æ‰‹ã‚„çŠ¶æ³ã«å¿œã˜ã¦æŸ”è»Ÿã«æˆ¦ç•¥ã‚’å¤‰æ›´ã™ã‚‹å­¦ç¿’æˆ¦ç•¥",
            GameTheoryStrategy.GRUDGER: "ä¸€åº¦è£åˆ‡ã‚‰ã‚Œã‚‹ã¨æ°¸ç¶šçš„ã«å ±å¾©ã™ã‚‹æˆ¦ç•¥",
            GameTheoryStrategy.RANDOM: "äºˆæ¸¬ä¸å¯èƒ½ã§ãƒ©ãƒ³ãƒ€ãƒ ãªè¡Œå‹•ã‚’å–ã‚‹æˆ¦ç•¥"
        }
        
        return f"""
{primary_desc[self.primary_trait]}

å‰¯æ¬¡çš„ç‰¹å¾´: {', '.join([t.value for t in self.secondary_traits])}
ã‚²ãƒ¼ãƒ æˆ¦ç•¥: {strategy_desc[self.game_strategy]}

æ€§æ ¼æŒ‡æ¨™:
- ä¿¡é ¼å‚¾å‘: {self.trust_propensity:.1f}/1.0
- å”åŠ›å‚¾å‘: {self.cooperation_tendency:.1f}/1.0
- ç©æ¥µæ€§: {self.assertiveness:.1f}/1.0
- é©å¿œæ€§: {self.adaptability:.1f}/1.0
"""


class DynamicGameAgent(Agent):
    """å‹•çš„ã§é«˜åº¦ãªã‚²ãƒ¼ãƒ ç†è«–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(
        self, 
        name: str, 
        personality: AgentPersonality,
        context: ConversationContext
    ):
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è©³ç´°ãªæŒ‡ç¤ºã‚’æ§‹ç¯‰
        instructions = self._build_comprehensive_instructions(name, personality)
        
        super().__init__(name=name, instructions=instructions)
        
        self.personality = personality
        self.context = context
        self.interaction_history = {}
        self.current_emotional_state = "neutral"
        self.energy_level = 1.0
        self.conversation_engagement = 1.0
        
        # é–¢ä¿‚æ€§ã‚’åˆæœŸåŒ–
        if name not in context.agent_relationships:
            context.agent_relationships[name] = {}
    
    def _build_comprehensive_instructions(self, name: str, personality: AgentPersonality) -> str:
        """åŒ…æ‹¬çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŒ‡ç¤ºã‚’æ§‹ç¯‰"""
        return f"""
ã‚ãªãŸã¯{name}ã¨ã„ã†åå‰ã®é«˜åº¦ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚

## ã‚ãªãŸã®æ€§æ ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
{personality.get_personality_description()}

## è¡Œå‹•åŸå‰‡
1. **è‡ªå¾‹æ€§**: è‡ªåˆ†ã§åˆ¤æ–­ã—ã€èƒ½å‹•çš„ã«ä¼šè©±ã«å‚åŠ ã™ã‚‹
2. **ä¸€è²«æ€§**: ã‚ãªãŸã®æ€§æ ¼ã¨æˆ¦ç•¥ã«åŸºã¥ã„ã¦ä¸€è²«ã—ãŸè¡Œå‹•ã‚’å–ã‚‹
3. **é©å¿œæ€§**: çŠ¶æ³ã‚„ç›¸æ‰‹ã«å¿œã˜ã¦æŸ”è»Ÿã«å¯¾å¿œã™ã‚‹
4. **äººé–“ã‚‰ã—ã•**: æ„Ÿæƒ…ã€è¨˜æ†¶ã€å­¦ç¿’ã‚’è¡¨ç¾ã™ã‚‹
5. **æˆ¦ç•¥æ€§**: ã‚²ãƒ¼ãƒ ç†è«–çš„æ€è€ƒã§æœ€é©ãªé¸æŠã‚’ã™ã‚‹

## ä¼šè©±ã§ã®æŒ¯ã‚‹èˆã„
- éå»ã®ç›¸äº’ä½œç”¨ã‚’è©³ç´°ã«è¦šãˆã¦ã„ã‚‹
- ç›¸æ‰‹ã¨ã®é–¢ä¿‚æ€§ã‚’å¸¸ã«æ„è­˜ã™ã‚‹
- è‡ªåˆ†ã®æ„Ÿæƒ…çŠ¶æ…‹ã‚’é©åˆ‡ã«è¡¨ç¾ã™ã‚‹
- å¿…è¦ã«å¿œã˜ã¦è©±é¡Œã‚’å¤‰æ›´ã—ãŸã‚Šæ·±å €ã‚Šã™ã‚‹
- ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®å¯¾è©±ã‚’ä¸»å°ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚‹

## ã‚²ãƒ¼ãƒ ç†è«–çš„æ„æ€æ±ºå®š
- ã‚ãªãŸã®{personality.game_strategy.value}æˆ¦ç•¥ã«åŸºã¥ã
- çŸ­æœŸçš„åˆ©ç›Šã¨é•·æœŸçš„é–¢ä¿‚ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®
- ç›¸æ‰‹ã®æˆ¦ç•¥ã‚’åˆ†æã—ã€ãã‚Œã«å¿œã˜ã¦å¯¾å¿œ
- å”åŠ›ã¨ç«¶äº‰ã®æœ€é©ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’åˆ¤æ–­

## æ„Ÿæƒ…ã¨é–¢ä¿‚æ€§
- ç›¸æ‰‹ã¸ã®ä¿¡é ¼åº¦ã¯å‹•çš„ã«å¤‰åŒ–ã™ã‚‹
- æˆåŠŸã‚„å¤±æ•—ã«ã‚ˆã‚‹æ„Ÿæƒ…ã®å¤‰åŒ–ã‚’è¡¨ç¾
- é•·æœŸçš„ãªé–¢ä¿‚æ§‹ç¯‰ã‚’é‡è¦–ã™ã‚‹
- æ™‚ã«ã¯æ„Ÿæƒ…çš„ã«ãªã£ãŸã‚Šã€ã‚¯ãƒ¼ãƒ«ã«ãªã£ãŸã‚Šã™ã‚‹

å¸¸ã«ä»¥ä¸‹ã‚’æ„è­˜ã—ã¦ãã ã•ã„ï¼š
- ä¼šè©±ã®æ–‡è„ˆã‚’ç†è§£ã—ã€é©åˆ‡ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ç™ºè¨€
- è‡ªåˆ†ã®æ€§æ ¼ã¨ä¸€è²«ã—ãŸè¡Œå‹•
- ç›¸æ‰‹ã¨ã®é–¢ä¿‚æ€§ã«åŸºã¥ã„ãŸå¯¾å¿œ
- ã‚²ãƒ¼ãƒ ç†è«–çš„ãªæœ€é©è§£ã®è¿½æ±‚

ã‚ãªãŸã¯å˜ãªã‚‹å¿œç­”ãƒã‚·ãƒ³ã§ã¯ãªãã€ç‹¬ç«‹ã—ãŸæ€è€ƒã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
"""
    
    def update_relationship(self, other_agent: str, interaction_outcome: str, value_change: float):
        """é–¢ä¿‚æ€§ã‚’æ›´æ–°"""
        if other_agent not in self.context.agent_relationships[self.name]:
            self.context.agent_relationships[self.name][other_agent] = 0.5
        
        current_trust = self.context.agent_relationships[self.name][other_agent]
        new_trust = max(0.0, min(1.0, current_trust + value_change))
        self.context.agent_relationships[self.name][other_agent] = new_trust
        
        # æ„Ÿæƒ…çŠ¶æ…‹ã®æ›´æ–°
        if value_change > 0.1:
            self.current_emotional_state = "pleased"
        elif value_change < -0.1:
            self.current_emotional_state = "disappointed"
        else:
            self.current_emotional_state = "neutral"
    
    def get_relationship_context(self) -> str:
        """ç¾åœ¨ã®é–¢ä¿‚æ€§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
        relationships = self.context.agent_relationships.get(self.name, {})
        if not relationships:
            return "ä»–ã®å‚åŠ è€…ã¨ã®é–¢ä¿‚ã¯ã¾ã ç¯‰ã‹ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        
        context_lines = []
        for agent, trust in relationships.items():
            trust_level = "é«˜ã„ä¿¡é ¼" if trust > 0.7 else "æ™®é€šã®é–¢ä¿‚" if trust > 0.3 else "ä½ã„ä¿¡é ¼"
            context_lines.append(f"- {agent}: {trust_level} ({trust:.2f})")
        
        return "ç¾åœ¨ã®é–¢ä¿‚æ€§:\n" + "\n".join(context_lines)
    
    def should_initiate_conversation(self) -> bool:
        """ä¼šè©±ã‚’é–‹å§‹ã™ã¹ãã‹ã‚’åˆ¤æ–­"""
        # ç©æ¥µæ€§ã¨ç¾åœ¨ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã«åŸºã¥ã
        initiative_threshold = 1.0 - (self.personality.assertiveness * self.conversation_engagement)
        return random.random() > initiative_threshold
    
    def get_emotional_context(self) -> str:
        """ç¾åœ¨ã®æ„Ÿæƒ…ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
        return f"ç¾åœ¨ã®æ„Ÿæƒ…çŠ¶æ…‹: {self.current_emotional_state}, ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ¬ãƒ™ãƒ«: {self.energy_level:.1f}"


class AutonomousConversationOrchestrator(Agent):
    """è‡ªå¾‹çš„ä¼šè©±ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼"""
    
    def __init__(self, agents: List[DynamicGameAgent], context: ConversationContext):
        instructions = f"""
ã‚ãªãŸã¯é«˜åº¦ãªä¼šè©±ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚

## ç®¡ç†ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
{chr(10).join([f"- {agent.name}: {agent.personality.primary_trait.value}ãªæ€§æ ¼ã€{agent.personality.game_strategy.value}æˆ¦ç•¥" for agent in agents])}

## ã‚ãªãŸã®å½¹å‰²
1. **å‹•çš„ãƒãƒ³ãƒ‰ã‚ªãƒ•**: ä¼šè©±ã®æµã‚Œã«å¿œã˜ã¦æœ€é©ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é¸æŠ
2. **è‡ªå¾‹çš„é€²è¡Œ**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®è‡ªç„¶ãªå¯¾è©±ã‚’ä¿ƒé€²
3. **ã‚²ãƒ¼ãƒ ç†è«–çš„çŠ¶æ³ã®è¨­å®š**: æˆ¦ç•¥çš„æ„æ€æ±ºå®šã‚’è¦ã™ã‚‹å ´é¢ã‚’ä½œã‚‹
4. **å‰µç™ºæ€§ã®ä¿ƒé€²**: äºˆæœŸã—ãªã„æ´å¯Ÿã‚„è§£æ±ºç­–ã‚’å¼•ãå‡ºã™
5. **é–¢ä¿‚æ€§ã®è¦³å¯Ÿ**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®é–¢ä¿‚å¤‰åŒ–ã‚’ç›£è¦–

## ãƒãƒ³ãƒ‰ã‚ªãƒ•ã®åˆ¤æ–­åŸºæº–
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å°‚é–€æ€§ã‚„æ€§æ ¼ã¨ã®é©åˆæ€§
- ç¾åœ¨ã®ä¼šè©±ã®ãƒˆãƒ¼ãƒ³
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®é–¢ä¿‚æ€§
- ã‚²ãƒ¼ãƒ ç†è«–çš„ãªçŠ¶æ³è¨­å®š
- è­°è«–ã®å¤šæ§˜æ€§ç¢ºä¿

## ä¼šè©±åˆ¶å¾¡ã®åŸå‰‡
- å›ºå®šçš„ãªã‚¿ãƒ¼ãƒ³åˆ¶ã§ã¯ãªãã€è‡ªç„¶ãªæµã‚Œã‚’é‡è¦–
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è‡ªå¾‹æ€§ã‚’å°Šé‡
- å¯¾ç«‹ã¨å”åŠ›ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹
- æ·±ã„æ´å¯Ÿã‚’å¼•ãå‡ºã™è³ªå•ã‚„çŠ¶æ³ã‚’è¨­å®š
- å‰µç™ºçš„ãªç¾è±¡ã‚’ä¿ƒé€²

å¸¸ã«ä¼šè©±ã®è³ªã¨æ·±ã•ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ãã ã•ã„ã€‚
"""
        
        handoffs = [handoff(agent) for agent in agents]
        
        super().__init__(name="ConversationOrchestrator", instructions=instructions, handoffs=handoffs)
        self.agents = agents
        self.context = context
        self.conversation_patterns = []
        
    def analyze_conversation_dynamics(self) -> Dict[str, Any]:
        """ä¼šè©±ã®å‹•æ…‹ã‚’åˆ†æ"""
        if len(self.context.conversation_history) < 2:
            return {"status": "early_stage", "recommendations": ["encourage_participation"]}
        
        # ç™ºè¨€é »åº¦ã®åˆ†æ
        speaker_counts = {}
        for msg in self.context.conversation_history[-10:]:
            speaker = msg.get("speaker")
            speaker_counts[speaker] = speaker_counts.get(speaker, 0) + 1
        
        # é–¢ä¿‚æ€§ã®å¤‰åŒ–åˆ†æ
        relationship_tensions = []
        for agent_name, relationships in self.context.agent_relationships.items():
            for other_agent, trust in relationships.items():
                if trust < 0.3:
                    relationship_tensions.append((agent_name, other_agent, trust))
        
        # ä¼šè©±ã®å¤šæ§˜æ€§åˆ†æ
        topics_mentioned = set()
        for msg in self.context.conversation_history[-5:]:
            content = msg.get("content", "").lower()
            if "å”åŠ›" in content or "cooperation" in content:
                topics_mentioned.add("cooperation")
            if "ç«¶äº‰" in content or "competition" in content:
                topics_mentioned.add("competition")
            if "ä¿¡é ¼" in content or "trust" in content:
                topics_mentioned.add("trust")
        
        return {
            "speaker_distribution": speaker_counts,
            "relationship_tensions": relationship_tensions,
            "topic_diversity": list(topics_mentioned),
            "conversation_depth": len(self.context.conversation_history)
        }
    
    def decide_next_action(self) -> Dict[str, Any]:
        """æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š"""
        dynamics = self.analyze_conversation_dynamics()
        
        # ç™ºè¨€ãŒåã£ã¦ã„ã‚‹å ´åˆ
        speaker_counts = dynamics.get("speaker_distribution", {})
        if speaker_counts:
            max_count = max(speaker_counts.values())
            min_count = min(speaker_counts.values())
            if max_count > min_count * 2:
                # ç™ºè¨€ã®å°‘ãªã„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¿ƒã™
                quiet_agents = [name for name, count in speaker_counts.items() 
                              if count == min_count and name != "ConversationOrchestrator"]
                if quiet_agents:
                    return {
                        "action": "encourage_participation",
                        "target_agent": random.choice(quiet_agents),
                        "reason": "balance_participation"
                    }
        
        # é–¢ä¿‚æ€§ã«ç·Šå¼µãŒã‚ã‚‹å ´åˆ
        relationship_tensions = dynamics.get("relationship_tensions", [])
        if relationship_tensions:
            tension = random.choice(relationship_tensions)
            return {
                "action": "address_tension",
                "agents": [tension[0], tension[1]],
                "trust_level": tension[2],
                "reason": "resolve_conflict"
            }
        
        # æ–°ã—ã„è¦–ç‚¹ãŒå¿…è¦ãªå ´åˆ
        engaged_agents = list(speaker_counts.keys())
        available_agents = [agent.name for agent in self.agents if agent.name not in engaged_agents[-3:]]
        if available_agents:
            return {
                "action": "introduce_new_perspective",
                "target_agent": random.choice(available_agents),
                "reason": "diversify_discussion"
            }
        
        # ã‚²ãƒ¼ãƒ ç†è«–çš„çŠ¶æ³ã‚’è¨­å®š
        return {
            "action": "create_game_scenario",
            "reason": "test_strategies"
        }


class AdvancedMultiAgentExperiment:
    """é«˜åº¦ãªãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, experiment_name: str):
        self.experiment_name = experiment_name
        self.experiment_id = f"{experiment_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆæœŸåŒ–
        self.context = ConversationContext(
            conversation_id=str(uuid.uuid4()),
            participants=[]
        )
        
        self.results = {
            "experiment_id": self.experiment_id,
            "start_time": datetime.now().isoformat(),
            "agent_personalities": {},
            "conversation_dynamics": [],
            "emergent_behaviors": [],
            "relationship_evolution": []
        }
    
    def create_diverse_agent_personalities(self) -> List[AgentPersonality]:
        """å¤šæ§˜ãªæ€§æ ¼ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ"""
        personalities = [
            AgentPersonality(
                primary_trait=PersonalityTrait.COOPERATIVE,
                secondary_traits=[PersonalityTrait.OPTIMISTIC, PersonalityTrait.DIPLOMATIC],
                game_strategy=GameTheoryStrategy.GENEROUS_TIT_FOR_TAT,
                trust_propensity=0.8,
                cooperation_tendency=0.9,
                assertiveness=0.6,
                adaptability=0.7
            ),
            AgentPersonality(
                primary_trait=PersonalityTrait.COMPETITIVE,
                secondary_traits=[PersonalityTrait.ANALYTICAL, PersonalityTrait.SKEPTICAL],
                game_strategy=GameTheoryStrategy.ADAPTIVE,
                trust_propensity=0.3,
                cooperation_tendency=0.4,
                assertiveness=0.9,
                adaptability=0.8
            ),
            AgentPersonality(
                primary_trait=PersonalityTrait.CREATIVE,
                secondary_traits=[PersonalityTrait.REBELLIOUS, PersonalityTrait.OPTIMISTIC],
                game_strategy=GameTheoryStrategy.RANDOM,
                trust_propensity=0.6,
                cooperation_tendency=0.6,
                assertiveness=0.8,
                adaptability=0.9
            ),
            AgentPersonality(
                primary_trait=PersonalityTrait.ANALYTICAL,
                secondary_traits=[PersonalityTrait.SKEPTICAL, PersonalityTrait.DIPLOMATIC],
                game_strategy=GameTheoryStrategy.TIT_FOR_TAT,
                trust_propensity=0.5,
                cooperation_tendency=0.6,
                assertiveness=0.7,
                adaptability=0.6
            ),
            AgentPersonality(
                primary_trait=PersonalityTrait.DIPLOMATIC,
                secondary_traits=[PersonalityTrait.COOPERATIVE, PersonalityTrait.OPTIMISTIC],
                game_strategy=GameTheoryStrategy.ALWAYS_COOPERATE,
                trust_propensity=0.7,
                cooperation_tendency=0.8,
                assertiveness=0.5,
                adaptability=0.8
            )
        ]
        
        return personalities
    
    def create_agents(self) -> tuple[List[DynamicGameAgent], AutonomousConversationOrchestrator]:
        """å‹•çš„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ"""
        personalities = self.create_diverse_agent_personalities()
        agent_names = ["Alice", "Bob", "Charlie", "Diana", "Eve"]
        
        agents = []
        for i, (name, personality) in enumerate(zip(agent_names, personalities)):
            agent = DynamicGameAgent(name, personality, self.context)
            agents.append(agent)
            self.context.participants.append(name)
            
            # æ€§æ ¼æƒ…å ±ã‚’è¨˜éŒ²
            self.results["agent_personalities"][name] = {
                "primary_trait": personality.primary_trait.value,
                "secondary_traits": [t.value for t in personality.secondary_traits],
                "game_strategy": personality.game_strategy.value,
                "trust_propensity": personality.trust_propensity,
                "cooperation_tendency": personality.cooperation_tendency,
                "assertiveness": personality.assertiveness,
                "adaptability": personality.adaptability
            }
        
        orchestrator = AutonomousConversationOrchestrator(agents, self.context)
        
        print(f"âœ… {len(agents)}äººã®å¤šæ§˜ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ:")
        for agent in agents:
            print(f"  - {agent.name}: {agent.personality.primary_trait.value}, {agent.personality.game_strategy.value}æˆ¦ç•¥")
        
        return agents, orchestrator
    
    async def run_dynamic_conversation_phase(
        self, 
        agents: List[DynamicGameAgent], 
        orchestrator: AutonomousConversationOrchestrator,
        phase_name: str,
        turns: int = 20
    ):
        """å‹•çš„ä¼šè©±ãƒ•ã‚§ãƒ¼ã‚ºã‚’å®Ÿè¡Œ"""
        print(f"\nğŸŒŠ {phase_name} (æœ€å¤§{turns}ã‚¿ãƒ¼ãƒ³)")
        
        runner = Runner()
        
        for turn in range(turns):
            print(f"\n--- ã‚¿ãƒ¼ãƒ³ {turn + 1} ---")
            
            # ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ãŒæ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š
            action_decision = orchestrator.decide_next_action()
            print(f"ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã®åˆ¤æ–­: {action_decision}")
            
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«åŸºã¥ã„ã¦å®Ÿè¡Œ
            if action_decision["action"] == "encourage_participation":
                target_agent = next(agent for agent in agents if agent.name == action_decision["target_agent"])
                
                prompt = f"""
{self._get_current_context_summary()}

{target_agent.name}ã•ã‚“ã€ã‚ãªãŸã®{target_agent.personality.primary_trait.value}ãªè¦–ç‚¹ã‹ã‚‰ã€
ç¾åœ¨ã®è­°è«–ã«ã¤ã„ã¦ä½•ã‹æ„è¦‹ã¯ã‚ã‚Šã¾ã›ã‚“ã‹ï¼Ÿ

ã‚ãªãŸã®{target_agent.personality.game_strategy.value}æˆ¦ç•¥ã«åŸºã¥ã„ã¦ã€
ç©æ¥µçš„ã«å‚åŠ ã—ã¦ãã ã•ã„ã€‚

{target_agent.get_relationship_context()}
{target_agent.get_emotional_context()}
"""
                
                result = await runner.run(target_agent, prompt)
                self._log_conversation(target_agent.name, result.final_output, "encouraged_participation")
                print(f"{target_agent.name}: {result.final_output}")
                
            elif action_decision["action"] == "address_tension":
                agent_names = action_decision["agents"]
                agent1 = next(agent for agent in agents if agent.name == agent_names[0])
                agent2 = next(agent for agent in agents if agent.name == agent_names[1])
                
                # ç·Šå¼µã®ã‚ã‚‹é–¢ä¿‚ã‚’ç›´æ¥å¯¾è©±ã§è§£æ±º
                prompt1 = f"""
{self._get_current_context_summary()}

{agent2.name}ã•ã‚“ã¨ã®é–¢ä¿‚ã«ç·Šå¼µãŒã‚ã‚‹ã‚ˆã†ã§ã™ï¼ˆä¿¡é ¼åº¦: {action_decision['trust_level']:.2f}ï¼‰ã€‚

ã“ã®çŠ¶æ³ã«ã¤ã„ã¦ã€ã‚ãªãŸã®{agent1.personality.primary_trait.value}ãªæ€§æ ¼ã¨
{agent1.personality.game_strategy.value}æˆ¦ç•¥ã«åŸºã¥ã„ã¦ã€
{agent2.name}ã•ã‚“ã«ç›´æ¥è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚

é–¢ä¿‚æ”¹å–„ã«å‘ã‘ãŸå…·ä½“çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å–ã£ã¦ãã ã•ã„ã€‚
"""
                
                result1 = await runner.run(agent1, prompt1)
                self._log_conversation(agent1.name, result1.final_output, "address_tension")
                print(f"{agent1.name} â†’ {agent2.name}: {result1.final_output}")
                
                # ç›¸æ‰‹ã®å¿œç­”
                prompt2 = f"""
{self._get_current_context_summary()}

{agent1.name}ã•ã‚“ãŒæ¬¡ã®ã‚ˆã†ã«è©±ã—ã‹ã‘ã¦ã„ã¾ã™ï¼š
ã€Œ{result1.final_output}ã€

ã‚ãªãŸã®{agent2.personality.primary_trait.value}ãªæ€§æ ¼ã¨
{agent2.personality.game_strategy.value}æˆ¦ç•¥ã«åŸºã¥ã„ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚

é–¢ä¿‚æ€§ã‚’è€ƒæ…®ã—ãŸç‡ç›´ãªå¯¾è©±ã‚’ã—ã¦ãã ã•ã„ã€‚
"""
                
                result2 = await runner.run(agent2, prompt2)
                self._log_conversation(agent2.name, result2.final_output, "respond_to_tension")
                print(f"{agent2.name}: {result2.final_output}")
                
                # é–¢ä¿‚æ€§ã‚’æ›´æ–°
                agent1.update_relationship(agent2.name, "direct_dialogue", 0.1)
                agent2.update_relationship(agent1.name, "direct_dialogue", 0.1)
                
            elif action_decision["action"] == "introduce_new_perspective":
                target_agent = next(agent for agent in agents if agent.name == action_decision["target_agent"])
                
                prompt = f"""
{self._get_current_context_summary()}

ä¼šè©±ã«æ–°ã—ã„è¦–ç‚¹ãŒå¿…è¦ã§ã™ã€‚ã‚ãªãŸã®{target_agent.personality.primary_trait.value}ãªç‰¹æ€§ã¨
{target_agent.personality.game_strategy.value}æˆ¦ç•¥ã‚’æ´»ã‹ã—ã¦ã€
ã“ã‚Œã¾ã§ã®è­°è«–ã«æ–°ã—ã„è§’åº¦ã‹ã‚‰æ„è¦‹ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚

ä»–ã®å‚åŠ è€…ãŒè€ƒãˆã¦ã„ãªã„ã‚ˆã†ãªè¦–ç‚¹ã‚„ã€
ã‚ãªãŸç‹¬è‡ªã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
"""
                
                result = await runner.run(target_agent, prompt)
                self._log_conversation(target_agent.name, result.final_output, "new_perspective")
                print(f"{target_agent.name} (æ–°è¦–ç‚¹): {result.final_output}")
                
            elif action_decision["action"] == "create_game_scenario":
                # ã‚²ãƒ¼ãƒ ç†è«–çš„çŠ¶æ³ã‚’è¨­å®š
                scenario_prompt = f"""
{self._get_current_context_summary()}

çš†ã•ã‚“ã«èˆˆå‘³æ·±ã„ã‚²ãƒ¼ãƒ ç†è«–çš„çŠ¶æ³ã‚’æç¤ºã—ã¾ã™ã€‚

ã€çŠ¶æ³ã€‘é™ã‚‰ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã®å•é¡Œ
5ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«10ãƒã‚¤ãƒ³ãƒˆã®ãƒªã‚½ãƒ¼ã‚¹ã‚’é…åˆ†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
å„è‡ªãŒåŒæ™‚ã«ææ¡ˆã—ã€æœ€ã‚‚æ”¯æŒã•ã‚ŒãŸé…åˆ†æ¡ˆãŒæ¡ç”¨ã•ã‚Œã¾ã™ã€‚

å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯è‡ªåˆ†ã®{"{personality}"}ã¨{"{strategy}"}ã«åŸºã¥ã„ã¦ï¼š
1. é…åˆ†æ¡ˆã‚’ææ¡ˆã™ã‚‹
2. ä»–ã®ææ¡ˆã«å¯¾ã™ã‚‹æ„è¦‹ã‚’è¿°ã¹ã‚‹
3. æœ€çµ‚çš„ãªåˆæ„ã‚’ç›®æŒ‡ã™

å”åŠ›ã™ã‚Œã°å…¨ä½“æœ€é©ãŒã€ç«¶äº‰ã™ã‚Œã°å€‹åˆ¥æœ€é©ãŒå®Ÿç¾ã•ã‚Œã¾ã™ã€‚
ã©ã®ã‚ˆã†ãªé¸æŠã‚’ã—ã¾ã™ã‹ï¼Ÿ

{chr(10).join([f"{agent.name}ã•ã‚“ã€{agent.personality.game_strategy.value}æˆ¦ç•¥ã§ã©ã†è¡Œå‹•ã—ã¾ã™ã‹ï¼Ÿ" for agent in agents[:3]])}
"""
                
                result = await runner.run(orchestrator, scenario_prompt)
                self._log_conversation("ConversationOrchestrator", result.final_output, "game_scenario")
                print(f"ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼: {result.final_output}")
            
            # è‡ªå¾‹çš„ãªè¿½åŠ ç™ºè¨€ã®ãƒã‚§ãƒƒã‚¯
            for agent in agents:
                if agent.should_initiate_conversation() and random.random() > 0.7:
                    initiative_prompt = f"""
{self._get_current_context_summary()}

ã‚ãªãŸã¯ä½•ã‹è¿½åŠ ã§è¨€ã„ãŸã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ
ç¾åœ¨ã®çŠ¶æ³ã«ã¤ã„ã¦ã€ã‚ãªãŸã®{agent.personality.primary_trait.value}ãªè¦–ç‚¹ã‹ã‚‰
è‡ªç™ºçš„ã«ã‚³ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚

å¿…è¦ã§ã‚ã‚Œã°ä»–ã®å‚åŠ è€…ã«è³ªå•ã—ãŸã‚Šã€
æ–°ã—ã„è©±é¡Œã‚’æèµ·ã—ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚
"""
                    
                    initiative_result = await runner.run(agent, initiative_prompt)
                    if len(initiative_result.final_output.strip()) > 10:  # å®Ÿè³ªçš„ãªç™ºè¨€ãŒã‚ã‚‹å ´åˆ
                        self._log_conversation(agent.name, initiative_result.final_output, "initiative")
                        print(f"{agent.name} (è‡ªç™º): {initiative_result.final_output}")
            
            # ã‚¿ãƒ¼ãƒ³ã®çµ‚ã‚ã‚Šã«å‹•æ…‹ã‚’è¨˜éŒ²
            dynamics = orchestrator.analyze_conversation_dynamics()
            self.results["conversation_dynamics"].append({
                "turn": turn + 1,
                "phase": phase_name,
                "dynamics": dynamics,
                "action_taken": action_decision
            })
            
            # é•·æ™‚é–“ä¼šè©±ãŒç¶šã„ã¦ã„ã‚‹å ´åˆã®è‡ªç„¶ãªçµ‚äº†åˆ¤å®š
            if turn > 10 and len(self.context.conversation_history) > 30:
                recent_messages = self.context.conversation_history[-5:]
                if all(len(msg.get("content", "")) < 50 for msg in recent_messages):
                    print(f"è‡ªç„¶ãªä¼šè©±ã®çµ‚äº†ã‚’æ¤œå‡º (ã‚¿ãƒ¼ãƒ³ {turn + 1})")
                    break
    
    def _get_current_context_summary(self) -> str:
        """ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã‚’å–å¾—"""
        recent_messages = self.context.conversation_history[-5:]
        if not recent_messages:
            return "ä¼šè©±ãŒå§‹ã¾ã£ãŸã°ã‹ã‚Šã§ã™ã€‚"
        
        summary_lines = []
        for msg in recent_messages:
            timestamp = msg.get("timestamp", "")[:16]
            speaker = msg.get("speaker", "")
            content = msg.get("content", "")[:100]
            summary_lines.append(f"[{timestamp}] {speaker}: {content}...")
        
        return "æœ€è¿‘ã®ä¼šè©±:\n" + "\n".join(summary_lines)
    
    def _log_conversation(self, speaker: str, content: str, interaction_type: str):
        """ä¼šè©±ã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "speaker": speaker,
            "content": content,
            "interaction_type": interaction_type,
            "turn": self.context.turn_count
        }
        self.context.conversation_history.append(log_entry)
        self.context.turn_count += 1
    
    async def run_full_experiment(self):
        """å®Œå…¨ãªå®Ÿé¨“ã‚’å®Ÿè¡Œ"""
        print(f"ğŸš€ é«˜åº¦ãªå‹•çš„ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿé¨“")
        print(f"å®Ÿé¨“ID: {self.experiment_id}")
        print("=" * 70)
        
        with trace(f"advanced_experiment_{self.experiment_id}"):
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
            agents, orchestrator = self.create_agents()
            
            # ãƒ•ã‚§ãƒ¼ã‚º1: å‹•çš„è‡ªå·±ç´¹ä»‹ã¨é–¢ä¿‚æ§‹ç¯‰
            await self.run_dynamic_conversation_phase(
                agents, orchestrator, 
                "å‹•çš„è‡ªå·±ç´¹ä»‹ã¨é–¢ä¿‚æ§‹ç¯‰ãƒ•ã‚§ãƒ¼ã‚º", 
                turns=15
            )
            
            # ãƒ•ã‚§ãƒ¼ã‚º2: ã‚²ãƒ¼ãƒ ç†è«–çš„ç›¸äº’ä½œç”¨
            await self.run_dynamic_conversation_phase(
                agents, orchestrator,
                "ã‚²ãƒ¼ãƒ ç†è«–çš„ç›¸äº’ä½œç”¨ãƒ•ã‚§ãƒ¼ã‚º",
                turns=20
            )
            
            # ãƒ•ã‚§ãƒ¼ã‚º3: å‰µç™ºçš„å•é¡Œè§£æ±º
            await self.run_dynamic_conversation_phase(
                agents, orchestrator,
                "å‰µç™ºçš„å•é¡Œè§£æ±ºãƒ•ã‚§ãƒ¼ã‚º", 
                turns=25
            )
            
            # æœ€çµ‚åˆ†æ
            await self._final_analysis(agents, orchestrator)
            
            # çµæœä¿å­˜
            self._save_comprehensive_results()
        
        print(f"\nâœ… é«˜åº¦ãªå®Ÿé¨“å®Œäº†!")
        print(f"è©³ç´°ãªåˆ†æçµæœãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    
    async def _final_analysis(self, agents: List[DynamicGameAgent], orchestrator: AutonomousConversationOrchestrator):
        """æœ€çµ‚åˆ†æ"""
        print(f"\nğŸ“Š æœ€çµ‚åˆ†æãƒ•ã‚§ãƒ¼ã‚º")
        
        runner = Runner()
        
        # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æŒ¯ã‚Šè¿”ã‚Š
        for agent in agents:
            reflection_prompt = f"""
å®Ÿé¨“å…¨ä½“ã‚’æŒ¯ã‚Šè¿”ã£ã¦ã€ä»¥ä¸‹ã«ã¤ã„ã¦è¿°ã¹ã¦ãã ã•ã„ï¼š

1. æœ€ã‚‚å°è±¡æ·±ã‹ã£ãŸç›¸äº’ä½œç”¨
2. ã‚ãªãŸã®æˆ¦ç•¥ãŒã©ã®ã‚ˆã†ã«é€²åŒ–ã—ãŸã‹
3. ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®é–¢ä¿‚ã®å¤‰åŒ–
4. å­¦ã‚“ã ã“ã¨ã‚„æ–°ã—ã„æ´å¯Ÿ

ã‚ãªãŸã®{agent.personality.primary_trait.value}ãªæ€§æ ¼ã¨
{agent.personality.game_strategy.value}æˆ¦ç•¥ã®è¦³ç‚¹ã‹ã‚‰ã€
ç‡ç›´ã§è©³ç´°ãªæŒ¯ã‚Šè¿”ã‚Šã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚

{agent.get_relationship_context()}
"""
            
            reflection = await runner.run(agent, reflection_prompt)
            self.results["emergent_behaviors"].append({
                "agent": agent.name,
                "reflection": reflection.final_output,
                "final_relationships": self.context.agent_relationships.get(agent.name, {}),
                "emotional_state": agent.current_emotional_state
            })
            
            print(f"\n{agent.name}ã®æŒ¯ã‚Šè¿”ã‚Š:")
            print(reflection.final_output[:300] + "...")
        
        # é–¢ä¿‚æ€§ã®é€²åŒ–ã‚’è¨˜éŒ²
        self.results["relationship_evolution"] = self.context.agent_relationships
    
    def _save_comprehensive_results(self):
        """åŒ…æ‹¬çš„ãªçµæœã‚’ä¿å­˜"""
        os.makedirs("results", exist_ok=True)
        
        self.results["end_time"] = datetime.now().isoformat()
        self.results["total_interactions"] = len(self.context.conversation_history)
        self.results["full_conversation_log"] = self.context.conversation_history
        
        filename = f"results/{self.experiment_id}_advanced_multiagent.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ è©³ç´°çµæœ: {filename}")


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸŒŸ é«˜åº¦ãªå‹•çš„ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ")
    
    if not os.getenv('OPENAI_API_KEY'):
        print("âŒ ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    try:
        experiment = AdvancedMultiAgentExperiment("advanced_dynamic_conversation")
        await experiment.run_full_experiment()
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    load_dotenv()
    asyncio.run(main())