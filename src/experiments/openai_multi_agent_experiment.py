"""OpenAI Agents SDKã‚’ä½¿ç”¨ã—ãŸãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿé¨“"""

import asyncio
import json
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path
import numpy as np

from agents import Runner, RunConfig
from agents.tracing import trace, TraceProcessor
from agents.types import TraceEvent

from ..agents.openai_game_agent import GameTheoryAgent, CoordinatorAgent, create_agent_with_handoffs
from ..game_theory.strategies import Strategy, Action
from ..game_theory.games import GameType, Game, PrisonersDilemma, PublicGoodsGame, KnowledgeSharingGame
from ..game_theory.payoff import calculate_payoff
from ..knowledge.exchange import KnowledgeItem
from ..utils.experiment_logger import ExperimentLogger
from ..utils.visualizer import GameVisualizer


class ExperimentTraceProcessor(TraceProcessor):
    """å®Ÿé¨“ç”¨ã®ãƒˆãƒ¬ãƒ¼ã‚¹å‡¦ç†"""
    
    def __init__(self, experiment_id: str):
        self.experiment_id = experiment_id
        self.traces = []
    
    def process(self, event: TraceEvent):
        """ãƒˆãƒ¬ãƒ¼ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†"""
        trace_data = {
            "experiment_id": self.experiment_id,
            "timestamp": datetime.now().isoformat(),
            "event_type": event.type,
            "data": event.data
        }
        self.traces.append(trace_data)
        
        # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
        if event.type in ["agent_decision", "handoff", "knowledge_share"]:
            print(f"[TRACE] {event.type}: {event.data.get('agent', 'unknown')} -> {event.data.get('action', 'unknown')}")
    
    def save_traces(self, filepath: str):
        """ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ä¿å­˜"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.traces, f, ensure_ascii=False, indent=2)


class MultiAgentExperiment:
    """ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿé¨“ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, experiment_name: str):
        self.experiment_name = experiment_name
        self.experiment_id = f"{experiment_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.logger = ExperimentLogger(self.experiment_id)
        self.visualizer = GameVisualizer()
        self.trace_processor = ExperimentTraceProcessor(self.experiment_id)
        
        # çµæœä¿å­˜ç”¨
        self.results = {
            "experiment_id": self.experiment_id,
            "experiment_name": experiment_name,
            "start_time": datetime.now().isoformat(),
            "agents": {},
            "games": [],
            "knowledge_exchanges": [],
            "emergent_solutions": []
        }
    
    def create_diverse_agents(self) -> List[GameTheoryAgent]:
        """å¤šæ§˜ãªæ€§æ ¼ã¨æˆ¦ç•¥ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ"""
        agent_configs = [
            ("Alice", Strategy.COOPERATIVE, "å”åŠ›çš„ã§ä¿¡é ¼ã‚’é‡è¦–ã™ã‚‹"),
            ("Bob", Strategy.COMPETITIVE, "ç«¶äº‰çš„ã§è‡ªå·±åˆ©ç›Šã‚’å„ªå…ˆã™ã‚‹"),
            ("Charlie", Strategy.TIT_FOR_TAT, "ç›¸äº’ä¸»ç¾©çš„ã§å…¬å¹³ã‚’é‡è¦–ã™ã‚‹"),
            ("Diana", Strategy.ADAPTIVE, "é©å¿œçš„ã§çŠ¶æ³ã«å¿œã˜ã¦æŸ”è»Ÿã«å¯¾å¿œã™ã‚‹"),
            ("Eve", Strategy.RANDOM, "äºˆæ¸¬ä¸å¯èƒ½ã§å‰µé€ çš„ãª"),
        ]
        
        agents = []
        for name, strategy, personality in agent_configs:
            agent = GameTheoryAgent(
                name=name,
                strategy=strategy,
                personality=personality,
                trust_threshold=0.6
            )
            agents.append(agent)
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæƒ…å ±ã‚’è¨˜éŒ²
            self.results["agents"][name] = {
                "strategy": strategy.value,
                "personality": personality,
                "trust_threshold": agent.trust_threshold
            }
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®ãƒãƒ³ãƒ‰ã‚ªãƒ•ã‚’è¨­å®š
        agents = create_agent_with_handoffs(agents, allow_self_handoff=False)
        
        return agents
    
    async def run_game_theory_interaction(
        self,
        agents: List[GameTheoryAgent],
        game_type: GameType,
        rounds: int = 10
    ) -> Dict[str, Any]:
        """ã‚²ãƒ¼ãƒ ç†è«–çš„ç›¸äº’ä½œç”¨ã‚’å®Ÿè¡Œ"""
        print(f"\nğŸ® ã‚²ãƒ¼ãƒ é–‹å§‹: {game_type.value}")
        
        game_result = {
            "game_type": game_type.value,
            "rounds": rounds,
            "interactions": [],
            "final_scores": {},
            "cooperation_rates": {}
        }
        
        # ã‚²ãƒ¼ãƒ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        if game_type == GameType.PRISONERS_DILEMMA:
            game = PrisonersDilemma()
        elif game_type == GameType.PUBLIC_GOODS:
            game = PublicGoodsGame()
        elif game_type == GameType.KNOWLEDGE_SHARING:
            game = KnowledgeSharingGame()
        else:
            raise ValueError(f"Unknown game type: {game_type}")
        
        # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¹ã‚³ã‚¢ã‚’åˆæœŸåŒ–
        scores = {agent.name: 0.0 for agent in agents}
        cooperation_counts = {agent.name: 0 for agent in agents}
        
        # ãƒ©ã‚¦ãƒ³ãƒ‰ã”ã¨ã«å®Ÿè¡Œ
        for round_num in range(rounds):
            print(f"\n  ãƒ©ã‚¦ãƒ³ãƒ‰ {round_num + 1}/{rounds}")
            round_interactions = []
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒšã‚¢ã”ã¨ã«å¯¾æˆ¦
            for i in range(len(agents)):
                for j in range(i + 1, len(agents)):
                    agent1, agent2 = agents[i], agents[j]
                    
                    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æº–å‚™
                    context = {
                        "round": round_num + 1,
                        "total_rounds": rounds,
                        "current_scores": scores.copy(),
                        "game_description": game.get_description()
                    }
                    
                    # ä¸¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ„æ€æ±ºå®š
                    with trace(name="game_interaction", tags={"round": round_num + 1}):
                        action1 = await agent1.make_decision(game_type, agent2.name, context)
                        action2 = await agent2.make_decision(game_type, agent1.name, context)
                    
                    # åˆ©å¾—ã‚’è¨ˆç®—
                    payoff1, payoff2 = calculate_payoff(game_type, action1, action2)
                    
                    # ã‚¹ã‚³ã‚¢ã‚’æ›´æ–°
                    scores[agent1.name] += payoff1
                    scores[agent2.name] += payoff2
                    
                    # å”åŠ›å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                    if action1 == Action.COOPERATE:
                        cooperation_counts[agent1.name] += 1
                    if action2 == Action.COOPERATE:
                        cooperation_counts[agent2.name] += 1
                    
                    # ä¿¡é ¼ã‚¹ã‚³ã‚¢ã‚’æ›´æ–°
                    agent1.update_trust(agent2.name, action2, action1)
                    agent2.update_trust(agent1.name, action1, action2)
                    
                    # ç›¸äº’ä½œç”¨ã‚’è¨˜éŒ²
                    interaction = {
                        "round": round_num + 1,
                        "agent1": agent1.name,
                        "agent2": agent2.name,
                        "action1": action1.value,
                        "action2": action2.value,
                        "payoff1": payoff1,
                        "payoff2": payoff2
                    }
                    round_interactions.append(interaction)
                    
                    print(f"    {agent1.name} vs {agent2.name}: "
                          f"{action1.value} vs {action2.value} "
                          f"(åˆ©å¾—: {payoff1:.1f}, {payoff2:.1f})")
            
            game_result["interactions"].extend(round_interactions)
        
        # æœ€çµ‚çµæœã‚’è¨ˆç®—
        total_interactions = rounds * (len(agents) * (len(agents) - 1) // 2)
        game_result["final_scores"] = scores
        game_result["cooperation_rates"] = {
            name: count / (rounds * (len(agents) - 1))
            for name, count in cooperation_counts.items()
        }
        
        self.results["games"].append(game_result)
        
        print(f"\nğŸ“Š ã‚²ãƒ¼ãƒ çµæœ:")
        for name, score in sorted(scores.items(), key=lambda x: x[1], reverse=True):
            coop_rate = game_result["cooperation_rates"][name]
            print(f"  {name}: ã‚¹ã‚³ã‚¢ {score:.1f}, å”åŠ›ç‡ {coop_rate:.2%}")
        
        return game_result
    
    async def run_knowledge_sharing_session(
        self,
        agents: List[GameTheoryAgent],
        coordinator: CoordinatorAgent,
        topic: str
    ) -> Dict[str, Any]:
        """çŸ¥è­˜å…±æœ‰ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        print(f"\nğŸ§  çŸ¥è­˜å…±æœ‰ã‚»ãƒƒã‚·ãƒ§ãƒ³: {topic}")
        
        session_result = {
            "topic": topic,
            "timestamp": datetime.now().isoformat(),
            "knowledge_exchanges": [],
            "discussion_summary": None
        }
        
        # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«åˆæœŸçŸ¥è­˜ã‚’ä¸ãˆã‚‹
        for i, agent in enumerate(agents):
            initial_knowledge = KnowledgeItem(
                content=f"{agent.name}ã®å°‚é–€çŸ¥è­˜: {topic}ã«é–¢ã™ã‚‹è¦³ç‚¹{i+1}",
                source=agent.name,
                value=np.random.uniform(0.5, 1.0),
                timestamp=datetime.now()
            )
            agent.add_knowledge(initial_knowledge)
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã§çŸ¥è­˜ã‚’å…±æœ‰
        print("  çŸ¥è­˜äº¤æ›ãƒ•ã‚§ãƒ¼ã‚º:")
        for agent in agents:
            for other_agent in agents:
                if agent.name != other_agent.name:
                    knowledge = agent.share_knowledge(other_agent.name)
                    if knowledge:
                        other_agent.add_knowledge(knowledge)
                        exchange = {
                            "from": agent.name,
                            "to": other_agent.name,
                            "knowledge": knowledge.content,
                            "trust_score": agent.memory.trust_scores.get(other_agent.name, 0.5)
                        }
                        session_result["knowledge_exchanges"].append(exchange)
                        print(f"    {agent.name} â†’ {other_agent.name}: çŸ¥è­˜ã‚’å…±æœ‰")
        
        # ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ãŒè­°è«–ã‚’ä¿ƒé€²
        context = {
            "agents": [agent.name for agent in agents],
            "topic": topic,
            "knowledge_exchanges": len(session_result["knowledge_exchanges"]),
            "average_trust": np.mean([
                trust for agent in agents 
                for trust in agent.memory.trust_scores.values()
            ])
        }
        
        discussion = await coordinator.facilitate_discussion(topic, context)
        session_result["discussion_summary"] = discussion
        
        self.results["knowledge_exchanges"].append(session_result)
        
        print(f"  çŸ¥è­˜äº¤æ›æ•°: {len(session_result['knowledge_exchanges'])}")
        print(f"  è­°è«–ã®è¦ç´„: {discussion['discussion'][:200]}...")
        
        return session_result
    
    async def run_complex_problem_solving(
        self,
        agents: List[GameTheoryAgent],
        coordinator: CoordinatorAgent,
        problem: str
    ) -> Dict[str, Any]:
        """è¤‡é›‘ãªå•é¡Œè§£æ±ºã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ"""
        print(f"\nğŸ¯ è¤‡é›‘ãªå•é¡Œè§£æ±º: {problem}")
        
        problem_result = {
            "problem": problem,
            "timestamp": datetime.now().isoformat(),
            "individual_solutions": {},
            "emergent_solution": None,
            "evaluation": {}
        }
        
        # å€‹åˆ¥ã«ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
        print("  å€‹åˆ¥è§£æ±ºãƒ•ã‚§ãƒ¼ã‚º:")
        runner = Runner()
        for agent in agents:
            prompt = f"""
å•é¡Œ: {problem}

ã‚ãªãŸã®æˆ¦ç•¥ï¼ˆ{agent.strategy.value}ï¼‰ã¨æ€§æ ¼ã«åŸºã¥ã„ã¦ã€
ã“ã®å•é¡Œã«å¯¾ã™ã‚‹ç‹¬è‡ªã®è§£æ±ºç­–ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å­˜åœ¨ã‚‚è€ƒæ…®ã—ã€å”åŠ›ã®å¯èƒ½æ€§ã‚‚æ¤œè¨ã—ã¦ãã ã•ã„ã€‚
"""
            
            result = await runner.run(agent, prompt, config=RunConfig(
                max_token_count=300,
                save_sensitive_data=False
            ))
            
            problem_result["individual_solutions"][agent.name] = result.final_output
            print(f"    {agent.name}: è§£æ±ºç­–ã‚’ææ¡ˆ")
        
        # é›†å›£ã§ã®çµ±åˆ
        print("  çµ±åˆãƒ•ã‚§ãƒ¼ã‚º:")
        integration_context = {
            "problem": problem,
            "individual_solutions": problem_result["individual_solutions"]
        }
        
        emergent_discussion = await coordinator.facilitate_discussion(
            f"å•é¡Œã€Œ{problem}ã€ã®çµ±åˆçš„è§£æ±º",
            integration_context
        )
        
        problem_result["emergent_solution"] = emergent_discussion["discussion"]
        
        # å‰µç™ºæ€§ã®è©•ä¾¡
        problem_result["evaluation"] = self._evaluate_emergence(
            problem_result["individual_solutions"],
            problem_result["emergent_solution"]
        )
        
        self.results["emergent_solutions"].append(problem_result)
        
        print(f"  å‰µç™ºæ€§ã‚¹ã‚³ã‚¢: {problem_result['evaluation']['emergence_score']:.2f}")
        print(f"  çµ±åˆè§£æ±ºç­–: {problem_result['emergent_solution'][:200]}...")
        
        return problem_result
    
    def _evaluate_emergence(
        self,
        individual_solutions: Dict[str, str],
        emergent_solution: str
    ) -> Dict[str, Any]:
        """å‰µç™ºæ€§ã‚’è©•ä¾¡"""
        # ç°¡æ˜“çš„ãªè©•ä¾¡ï¼ˆå®Ÿéš›ã¯ã‚ˆã‚Šé«˜åº¦ãªè©•ä¾¡ãŒå¿…è¦ï¼‰
        individual_lengths = [len(sol) for sol in individual_solutions.values()]
        emergent_length = len(emergent_solution)
        
        # çµ±åˆè§£ãŒå€‹åˆ¥è§£ã‚ˆã‚Šè±Šã‹ã§ã‚ã‚‹ã‹ã‚’è©•ä¾¡
        richness_score = emergent_length / (np.mean(individual_lengths) + 1)
        
        # å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢ï¼ˆå€‹åˆ¥è§£ã®é•ã„ã‚’è€ƒæ…®ï¼‰
        diversity_score = len(set(individual_solutions.values())) / len(individual_solutions)
        
        # å‰µç™ºæ€§ã‚¹ã‚³ã‚¢
        emergence_score = min(1.0, (richness_score + diversity_score) / 2)
        
        return {
            "emergence_score": emergence_score,
            "richness_score": richness_score,
            "diversity_score": diversity_score,
            "individual_count": len(individual_solutions),
            "emergent_length": emergent_length
        }
    
    async def run_full_experiment(self):
        """å®Œå…¨ãªå®Ÿé¨“ã‚’å®Ÿè¡Œ"""
        print(f"\n{'='*60}")
        print(f"ğŸ”¬ å®Ÿé¨“é–‹å§‹: {self.experiment_name}")
        print(f"å®Ÿé¨“ID: {self.experiment_id}")
        print(f"{'='*60}")
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
        agents = self.create_diverse_agents()
        coordinator = CoordinatorAgent(managed_agents=agents)
        
        # 1. ã‚²ãƒ¼ãƒ ç†è«–çš„ç›¸äº’ä½œç”¨
        await self.run_game_theory_interaction(agents, GameType.PRISONERS_DILEMMA, rounds=10)
        await self.run_game_theory_interaction(agents, GameType.PUBLIC_GOODS, rounds=5)
        
        # 2. çŸ¥è­˜å…±æœ‰ã‚»ãƒƒã‚·ãƒ§ãƒ³
        await self.run_knowledge_sharing_session(
            agents, coordinator,
            "æŒç¶šå¯èƒ½ãªéƒ½å¸‚é–‹ç™ºã®æœ€é©åŒ–æˆ¦ç•¥"
        )
        
        # 3. è¤‡é›‘ãªå•é¡Œè§£æ±º
        complex_problems = [
            "æ°—å€™å¤‰å‹•ã¨çµŒæ¸ˆæˆé•·ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹æ”¿ç­–ç«‹æ¡ˆ",
            "AIã®å€«ç†çš„åˆ©ç”¨ã¨æŠ€è¡“é©æ–°ã®ä¸¡ç«‹",
            "ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªå¥åº·å±æ©Ÿã¸ã®å”èª¿çš„å¯¾å¿œã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ"
        ]
        
        for problem in complex_problems:
            await self.run_complex_problem_solving(agents, coordinator, problem)
        
        # 4. æœ€çµ‚çš„ãªä¿¡é ¼é–¢ä¿‚ã®åˆ†æ
        self._analyze_final_trust_network(agents)
        
        # çµæœã‚’ä¿å­˜
        self._save_results()
        
        print(f"\n{'='*60}")
        print(f"âœ… å®Ÿé¨“å®Œäº†: {self.experiment_name}")
        print(f"çµæœã¯ results/{self.experiment_id}/ ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        print(f"{'='*60}")
    
    def _analyze_final_trust_network(self, agents: List[GameTheoryAgent]):
        """æœ€çµ‚çš„ãªä¿¡é ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆ†æ"""
        print("\nğŸ¤ æœ€çµ‚çš„ãªä¿¡é ¼é–¢ä¿‚:")
        
        trust_matrix = {}
        for agent in agents:
            trust_matrix[agent.name] = {}
            for other_agent in agents:
                if agent.name != other_agent.name:
                    trust = agent.memory.trust_scores.get(other_agent.name, 0.5)
                    trust_matrix[agent.name][other_agent.name] = trust
        
        # é«˜ä¿¡é ¼é–¢ä¿‚ã‚’è¡¨ç¤º
        high_trust_pairs = []
        for agent1 in trust_matrix:
            for agent2 in trust_matrix[agent1]:
                trust = trust_matrix[agent1][agent2]
                if trust >= 0.7:
                    high_trust_pairs.append((agent1, agent2, trust))
        
        if high_trust_pairs:
            print("  é«˜ä¿¡é ¼é–¢ä¿‚ (â‰¥0.7):")
            for agent1, agent2, trust in sorted(high_trust_pairs, key=lambda x: x[2], reverse=True):
                print(f"    {agent1} â†’ {agent2}: {trust:.2f}")
        
        self.results["final_trust_network"] = trust_matrix
    
    def _save_results(self):
        """å®Ÿé¨“çµæœã‚’ä¿å­˜"""
        # çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        result_dir = Path(f"results/{self.experiment_id}")
        result_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ¡ã‚¤ãƒ³çµæœã‚’ä¿å­˜
        self.results["end_time"] = datetime.now().isoformat()
        with open(result_dir / "experiment_results.json", 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        # ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ä¿å­˜
        self.trace_processor.save_traces(str(result_dir / "traces.json"))
        
        # å¯è¦–åŒ–ã‚’ç”Ÿæˆ
        try:
            self.visualizer.create_experiment_report(self.results)
            print(f"  ğŸ“Š å¯è¦–åŒ–ã‚’ç”Ÿæˆ: {result_dir}/plots/")
        except Exception as e:
            print(f"  âš ï¸ å¯è¦–åŒ–ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    if not os.getenv('OPENAI_API_KEY'):
        print("âŒ ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    # å®Ÿé¨“ã‚’å®Ÿè¡Œ
    experiment = MultiAgentExperiment("å‰µç™ºçš„å•é¡Œè§£æ±ºå®Ÿé¨“")
    await experiment.run_full_experiment()


if __name__ == "__main__":
    asyncio.run(main())