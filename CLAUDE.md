# é€²åŒ–çš„ç¾¤çŸ¥èƒ½ã«åŸºã¥ãLoRAã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé›†å›£ã®å”èª¿çš„æœ€é©åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ã€Œé€²åŒ–çš„ç¾¤çŸ¥èƒ½ã«åŸºã¥ãLoRAã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé›†å›£ã®å”èª¿çš„æœ€é©åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯: ã‚²ãƒ¼ãƒ ç†è«–çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚‹å‹•çš„çŸ¥è­˜é€²åŒ–ã¨å‰µç™ºçš„å•é¡Œè§£æ±ºã€ã¨ã„ã†ä¿®å£«ç ”ç©¶ã®å®Ÿè£…ã§ã™ã€‚

### ç ”ç©¶ç›®çš„
- ã‚²ãƒ¼ãƒ ç†è«–ã«åŸºã¥ãã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒå£«ãŒçŸ¥è­˜ã‚’é€²åŒ–ã•ã›ã€å‹•çš„ãªé©å¿œèƒ½åŠ›ã‚’ç²å¾—
- ãƒ¡ã‚¿èªçŸ¥ãƒ»æ„æ€æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹ã®é€æ˜æ€§ã‚’å‘ä¸Š
- ã‚²ãƒ¼ãƒ ç†è«–çš„ãªç›¸äº’ä½œç”¨ã‚’é€šã˜ã¦å”èª¿çš„ã«çŸ¥è­˜ã‚’é€²åŒ–ã•ã›ã€å‰µç™ºçš„ãªå•é¡Œè§£æ±ºèƒ½åŠ›ã‚’å®Ÿç¾

### èƒŒæ™¯
- å·¨å¤§LLMãƒ¢ãƒ‡ãƒ«ã®é™ç•Œï¼šè¨ˆç®—ã‚³ã‚¹ãƒˆã€æ–°çŸ¥è­˜ã¸ã®é©å¿œã®ä½ã•ã€åˆ¤æ–­æ ¹æ‹ ã®ä¸é€æ˜æ€§
- ç¤¾ä¼šçš„å•é¡Œè§£æ±ºã«ã¯ã€Œã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ã«ã‚ˆã‚‹å”èª¿è¡Œå‹•ãŒä¸å¯æ¬ 
- ç”Ÿç‰©ç•Œã®ç¾¤çŸ¥èƒ½ã‚„é€²åŒ–ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ç€ç›®ã—ã€å¤šæ•°ã®å°è¦æ¨¡AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å”åŠ›ãƒ»ç«¶äº‰ã‚’é€šã˜ãŸå•é¡Œè§£æ±º

## æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯é¸å®š

èª¿æŸ»ã®çµæœã€ä»¥ä¸‹ã®ç†ç”±ã‹ã‚‰OpenAI Agents SDKã‚’æ¡ç”¨ï¼š

### OpenAI Agents SDKï¼ˆ2025å¹´3æœˆãƒªãƒªãƒ¼ã‚¹ï¼‰
- **é¸å®šç†ç”±**ï¼š
  - è»½é‡ã§å­¦ç¿’æ›²ç·šãŒç·©ã‚„ã‹ï¼ˆæ•°è¡Œã®ã‚³ãƒ¼ãƒ‰ã§é–‹å§‹å¯èƒ½ï¼‰
  - Handoffsã«ã‚ˆã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“é·ç§»ãŒæœ¬ç ”ç©¶ã®ã‚²ãƒ¼ãƒ ç†è«–çš„ç›¸äº’ä½œç”¨ã«æœ€é©
  - 100+ LLMã‚µãƒãƒ¼ãƒˆï¼ˆå°†æ¥çš„ãªãƒ­ãƒ¼ã‚«ãƒ«LLMç§»è¡ŒãŒå®¹æ˜“ï¼‰
  - å†…è”µãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°æ©Ÿèƒ½ã§æ„æ€æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹ã®é€æ˜æ€§ã‚’ç¢ºä¿
  - ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ¬ãƒ‡ã‚£ã§å®‰å®šæ€§ãŒé«˜ã„

### æ¯”è¼ƒæ¤œè¨ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- **LangGraph**: ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã§é«˜åº¦ãªåˆ¶å¾¡ãŒå¯èƒ½ã ãŒã€æœ¬ç ”ç©¶ã«ã¯è¤‡é›‘ã™ãã‚‹
- **Microsoft AutoGen**: GroupStrategyã‚’ã‚²ãƒ¼ãƒ ç†è«–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ç½®æ›å¯èƒ½ã ãŒã€é‡é‡ç´š
- **CrewAI**: ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•ã§é«˜é€Ÿã ãŒã€ã‚²ãƒ¼ãƒ ç†è«–çš„ç›¸äº’ä½œç”¨ã®å®Ÿè£…ãŒè¤‡é›‘

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
openai-multiagent/
â”œâ”€â”€ pyproject.toml          # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šã¨ä¾å­˜é–¢ä¿‚
â”œâ”€â”€ README.md              # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
â”œâ”€â”€ CLAUDE.md              # æœ¬ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæŒ‡ç¤ºæ›¸ï¼‰
â”œâ”€â”€ main.py                # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents/            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®šç¾©
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_agent.py  # åŸºæœ¬ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¯ãƒ©ã‚¹
â”‚   â”‚   â”œâ”€â”€ game_agents.py # ã‚²ãƒ¼ãƒ ç†è«–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
â”‚   â”‚   â””â”€â”€ coordinator.py # èª¿æ•´ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ game_theory/       # ã‚²ãƒ¼ãƒ ç†è«–å®Ÿè£…
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ games.py       # ã‚²ãƒ¼ãƒ å®šç¾©ï¼ˆå›šäººã®ã‚¸ãƒ¬ãƒ³ãƒç­‰ï¼‰
â”‚   â”‚   â”œâ”€â”€ strategies.py  # æˆ¦ç•¥å®Ÿè£…ï¼ˆTFTã€Win-Stayç­‰ï¼‰
â”‚   â”‚   â””â”€â”€ payoff.py      # åˆ©å¾—è¨ˆç®—
â”‚   â”œâ”€â”€ evolution/         # é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ genetic.py     # éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
â”‚   â”‚   â””â”€â”€ fitness.py     # é©å¿œåº¦é–¢æ•°
â”‚   â”œâ”€â”€ knowledge/         # çŸ¥è­˜ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ exchange.py    # çŸ¥è­˜äº¤æ›ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
â”‚   â”‚   â””â”€â”€ trust.py       # ä¿¡é ¼ãƒ»è©•åˆ¤ã‚·ã‚¹ãƒ†ãƒ 
â”‚   â””â”€â”€ utils/             # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py      # ãƒ­ã‚®ãƒ³ã‚°
â”‚       â””â”€â”€ visualizer.py  # çµæœå¯è¦–åŒ–
â”œâ”€â”€ experiments/           # å®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ prisoner_dilemma.py
â”‚   â””â”€â”€ coordination_game.py
â”œâ”€â”€ tests/                 # ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_agents.py
â”‚   â”œâ”€â”€ test_game_theory.py
â”‚   â””â”€â”€ test_evolution.py
â””â”€â”€ results/               # å®Ÿé¨“çµæœä¿å­˜
    â””â”€â”€ .gitkeep
```

## å®Ÿè£…ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆ
```python
from agents import Agent, Runner

class GameTheoryAgent(Agent):
    def __init__(self, name, strategy, trust_threshold=0.5):
        super().__init__(
            name=name,
            instructions=f"You are a {strategy} player in game theory scenarios.",
            handoffs=[]  # å‹•çš„ã«è¨­å®š
        )
        self.strategy = strategy
        self.trust_scores = {}
        self.knowledge_base = []
```

### 2. ã‚²ãƒ¼ãƒ ç†è«–çš„ç›¸äº’ä½œç”¨
- **å›šäººã®ã‚¸ãƒ¬ãƒ³ãƒ**: å”åŠ›/è£åˆ‡ã‚Šã®åŸºæœ¬çš„ãªæ„æ€æ±ºå®š
- **å…¬å…±è²¡ã‚²ãƒ¼ãƒ **: é›†å›£ã§ã®å”èª¿è¡Œå‹•ã®å‰µç™º
- **çŸ¥è­˜å…±æœ‰ã‚²ãƒ¼ãƒ **: æƒ…å ±äº¤æ›ã«ãŠã‘ã‚‹ä¿¡é ¼ã¨ç«¶äº‰

### 3. é€²åŒ–ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
- å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æˆ¦ç•¥ã‚’ã€Œéºä¼å­ã€ã¨ã—ã¦æ‰±ã†
- é©å¿œåº¦ã«åŸºã¥ãé¸æŠãƒ»äº¤å‰ãƒ»çªç„¶å¤‰ç•°
- ä¸–ä»£äº¤ä»£ã«ã‚ˆã‚‹é›†å›£çŸ¥èƒ½ã®é€²åŒ–

### 4. å‰µç™ºçš„å•é¡Œè§£æ±ºãƒ—ãƒ­ã‚»ã‚¹
1. **ã‚¿ã‚¹ã‚¯æ²ç¤ºã¨è§£é‡ˆ**: å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç‹¬è‡ªã«å•é¡Œã‚’è§£é‡ˆ
2. **å€‹åˆ¥æ¨è«–ã¨è§£å€™è£œç”Ÿæˆ**: å„è‡ªã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰è§£ã‚’ç”Ÿæˆ
3. **ã‚²ãƒ¼ãƒ ç†è«–çš„ç›¸äº’ä½œç”¨**: å”åŠ›/ç«¶äº‰ã®æ„æ€æ±ºå®š
4. **çŸ¥è­˜äº¤æ›ã¨ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³**: ä¿¡é ¼ã«åŸºã¥ãæƒ…å ±å…±æœ‰
5. **é›†åˆçš„çŸ¥è­˜çµ±åˆ**: éƒ¨åˆ†è§£ã®çµ±åˆã¨æœ€é©åŒ–
6. **å‰µç™ºæ€§ã®è©•ä¾¡**: å˜ç‹¬ã§ã¯ä¸å¯èƒ½ãªè§£ã®ç”Ÿæˆã‚’ç¢ºèª

## å®Ÿè£…è¨ˆç”»

### ãƒ•ã‚§ãƒ¼ã‚º1: åŸºç¤å®Ÿè£…ï¼ˆç¾åœ¨ï¼‰
- OpenAI Agents SDKã‚’ä½¿ç”¨ã—ãŸåŸºæœ¬çš„ãªãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ 
- å›šäººã®ã‚¸ãƒ¬ãƒ³ãƒã®å®Ÿè£…
- ç°¡å˜ãªçŸ¥è­˜äº¤æ›ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

### ãƒ•ã‚§ãƒ¼ã‚º2: ã‚²ãƒ¼ãƒ ç†è«–æ‹¡å¼µ
- è¤‡æ•°ã®ã‚²ãƒ¼ãƒ ç†è«–ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…
- å‹•çš„æˆ¦ç•¥é¸æŠãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
- ä¿¡é ¼ãƒ»è©•åˆ¤ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰

### ãƒ•ã‚§ãƒ¼ã‚º3: é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çµ±åˆ
- éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹æˆ¦ç•¥é€²åŒ–
- é©å¿œåº¦é–¢æ•°ã®è¨­è¨ˆã¨æœ€é©åŒ–
- ä¸–ä»£äº¤ä»£ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

### ãƒ•ã‚§ãƒ¼ã‚º4: LoRAçµ±åˆï¼ˆå°†æ¥ï¼‰
- å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®LoRAãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‰²ã‚Šå½“ã¦
- LoRAã‚’ã€Œéºä¼å­ã€ã¨ã—ãŸé€²åŒ–
- ãƒ­ãƒ¼ã‚«ãƒ«LLMã§ã®å®Ÿè¡Œ

## é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# Pythonç’°å¢ƒã®æº–å‚™ï¼ˆPython 3.12æ¨å¥¨ï¼‰
uv venv
source .venv/bin/activate  # Linux/Mac
# ã¾ãŸã¯
.venv\Scripts\activate  # Windows

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv pip install -e .

# ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
export OPENAI_API_KEY="your-api-key"
```

## å®Ÿè¡Œæ–¹æ³•

```bash
# åŸºæœ¬çš„ãªå®Ÿè¡Œ
python main.py

# ç‰¹å®šã®å®Ÿé¨“ã‚’å®Ÿè¡Œ
python experiments/prisoner_dilemma.py

# ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
pytest tests/
```

## è©•ä¾¡æŒ‡æ¨™

1. **å”èª¿ç‡**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®å”åŠ›è¡Œå‹•ã®é »åº¦
2. **å•é¡Œè§£æ±ºç²¾åº¦**: ã‚¿ã‚¹ã‚¯ã®æˆåŠŸç‡ã¨å“è³ª
3. **å‰µç™ºæ€§ã‚¹ã‚³ã‚¢**: å€‹åˆ¥è§£ã¨é›†å›£è§£ã®æ€§èƒ½å·®
4. **é©å¿œé€Ÿåº¦**: æ–°ã—ã„å•é¡Œã¸ã®å¯¾å¿œé€Ÿåº¦
5. **çŸ¥è­˜å¤šæ§˜æ€§**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®çŸ¥è­˜ã®å¤šæ§˜æ€§

## æ³¨æ„äº‹é …

- APIã‚³ã‚¹ãƒˆã‚’è€ƒæ…®ã—ã€å°è¦æ¨¡ãªå®Ÿé¨“ã‹ã‚‰é–‹å§‹
- ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ã¦ãƒ‡ãƒãƒƒã‚°
- å®Ÿé¨“çµæœã¯`results/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«è‡ªå‹•ä¿å­˜
- ã‚²ãƒ¼ãƒ ç†è«–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯`config.yaml`ã§èª¿æ•´å¯èƒ½

## ä»Šå¾Œã®æ‹¡å¼µ

1. **Web UIã®è¿½åŠ **: å®Ÿé¨“ã®å¯è¦–åŒ–ã¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæ“ä½œ
2. **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµ±åˆ**: æ¨™æº–çš„ãªå•é¡Œã‚»ãƒƒãƒˆã§ã®è©•ä¾¡
3. **åˆ†æ•£å®Ÿè¡Œ**: å¤§è¦æ¨¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé›†å›£ã®ä¸¦åˆ—å‡¦ç†
4. **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’**: ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®å®Ÿè£…

## ãƒªãƒ³ã‚¯ã¨ã‚³ãƒãƒ³ãƒ‰

### é–‹ç™ºæ™‚ã®ä¸»è¦ã‚³ãƒãƒ³ãƒ‰
```bash
# ã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
uv run black src/ tests/

# å‹ãƒã‚§ãƒƒã‚¯
uv run mypy src/

# ãƒªãƒ³ãƒˆ
uv run ruff check src/

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
uv run pytest tests/ -v

# ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆ
uv run pytest --cov=src tests/
```

### å‚è€ƒãƒªãƒ³ã‚¯
- [OpenAI Agents SDK Documentation](https://openai.github.io/openai-agents-python/)
- [OpenAI Agents SDK GitHub](https://github.com/openai/openai-agents-python)
- [Game Theory and MARL Survey](https://arxiv.org/html/2412.20523v1)

## ç ”ç©¶ã®æ„ç¾©

æœ¬ç ”ç©¶ã¯ã€å˜ä¸€ã®å·¨å¤§LLMã«ä¾å­˜ã—ãªã„ã€ã‚ˆã‚ŠæŸ”è»Ÿã§é©å¿œçš„ãªAIã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿç¾ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚ç”Ÿç‰©ã®é€²åŒ–ã¨ç¾¤çŸ¥èƒ½ã®åŸç†ã‚’å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã§ã€è¨ˆç®—åŠ¹ç‡ã¨å•é¡Œè§£æ±ºèƒ½åŠ›ã®ä¸¡ç«‹ã‚’å›³ã‚Šã€æŒç¶šå¯èƒ½ãªAIæŠ€è¡“ã®ç™ºå±•ã«è²¢çŒ®ã—ã¾ã™ã€‚

---

# è©³ç´°å®Ÿè£…ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨è¨­è¨ˆæ–‡æ›¸

## 1. ãƒ¡ãƒ¢ãƒªåˆ†é›¢å‹ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ 

### 1.1 ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯ã€å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç‹¬ç«‹ã—ãŸãƒ¡ãƒ¢ãƒªã‚’æŒã¡ã€è‡ªåˆ†ã®ç™ºè¨€ã¨ç›´æ¥ã®å¿œç­”ã®ã¿ã‚’è¨˜æ†¶ã™ã‚‹å®Œå…¨åˆ†é›¢å‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚OpenAI Responses APIæº–æ‹ ã®ä¼šè©±å±¥æ­´å½¢å¼ã«ã‚ˆã‚Šã€çœŸã«äººé–“ã‚‰ã—ã„ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

### 1.2 æ ¸å¿ƒæŠ€è¡“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

#### 1.2.1 AgentMemory ã‚¯ãƒ©ã‚¹è¨­è¨ˆ

```python
@dataclass
class Message:
    """Responses APIæº–æ‹ ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼"""
    role: str  # "user" or "assistant" 
    content: str
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    message_id: str = field(default_factory=lambda: str(uuid.uuid4()))

@dataclass
class AgentMemory:
    """å€‹åˆ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¡ãƒ¢ãƒªï¼ˆå®Œå…¨åˆ†é›¢ï¼‰"""
    agent_id: str
    conversation_history: List[Message] = field(default_factory=list)
    direct_partners: set = field(default_factory=set)  # ç›´æ¥ä¼šè©±ã—ãŸç›¸æ‰‹
    
    def add_my_message(self, content: str) -> Message:
        """è‡ªåˆ†ã®ç™ºè¨€ã‚’è¿½åŠ """
        message = Message(role="assistant", content=content)
        self.conversation_history.append(message)
        return message
    
    def add_partner_message(self, partner_name: str, content: str) -> Message:
        """ç›¸æ‰‹ã‹ã‚‰ã®ç›´æ¥ã®ç™ºè¨€ã‚’è¿½åŠ """
        message = Message(role="user", content=f"[{partner_name}]: {content}")
        self.conversation_history.append(message)
        self.direct_partners.add(partner_name)
        return message
    
    def get_conversation_context(self, limit: int = 10) -> str:
        """è‡ªåˆ†ã®ä¼šè©±å±¥æ­´ã®ã¿ã‚’å–å¾—"""
        recent_messages = self.conversation_history[-limit:]
        if not recent_messages:
            return "ä¼šè©±å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        context_lines = []
        for msg in recent_messages:
            time_str = msg.timestamp[11:16]  # HH:MM
            if msg.role == "assistant":
                context_lines.append(f"[{time_str}] è‡ªåˆ†: {msg.content[:100]}...")
            else:
                context_lines.append(f"[{time_str}] {msg.content[:100]}...")
        
        return "ã‚ãªãŸã®è¨˜æ†¶ã™ã‚‹ä¼šè©±å±¥æ­´:\n" + "\n".join(context_lines)
    
    def get_responses_api_format(self) -> List[Dict[str, str]]:
        """Responses APIæº–æ‹ ã®å½¢å¼ã§å±¥æ­´ã‚’è¿”ã™"""
        return [
            {"role": msg.role, "content": msg.content}
            for msg in self.conversation_history
        ]
```

#### 1.2.2 ã‚²ãƒ¼ãƒ ç†è«–çš„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆ

```python
class PersonalityTrait(Enum):
    """æ€§æ ¼ç‰¹æ€§ - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºæœ¬çš„ãªè¡Œå‹•å‚¾å‘"""
    COOPERATIVE = "cooperative"      # å”åŠ›çš„ã§ä»–è€…ã¨ã®èª¿å’Œã‚’é‡è¦–
    COMPETITIVE = "competitive"      # ç«¶äº‰çš„ã§è‡ªå·±ã®åˆ©ç›Šã‚’è¿½æ±‚
    ANALYTICAL = "analytical"        # è«–ç†çš„ã§åˆ†æçš„æ€è€ƒã‚’é‡è¦–
    CREATIVE = "creative"           # å‰µé€ çš„ã§æ–°ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç”Ÿã¿å‡ºã™
    DIPLOMATIC = "diplomatic"       # å¤–äº¤çš„ã§èª¿æ•´ã‚’é‡è¦–

class GameStrategy(Enum):
    """ã‚²ãƒ¼ãƒ ç†è«–æˆ¦ç•¥ - å…·ä½“çš„ãªæ„æ€æ±ºå®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ """
    TIT_FOR_TAT = "tit_for_tat"                    # ç›¸æ‰‹ã®è¡Œå‹•ã‚’åæ˜ ã™ã‚‹å¿œå ±æˆ¦ç•¥
    ALWAYS_COOPERATE = "always_cooperate"          # å¸¸ã«å”åŠ›ã‚’é¸ã¶å¹³å’Œæˆ¦ç•¥
    ADAPTIVE = "adaptive"                          # çŠ¶æ³ã«å¿œã˜ã¦æŸ”è»Ÿã«æˆ¦ç•¥ã‚’å¤‰æ›´
    GENEROUS_TIT_FOR_TAT = "generous_tit_for_tat"  # å¿œå ±æˆ¦ç•¥ã ãŒæ™‚ã€…å¯›å®¹ã•ã‚’ç¤ºã™
    RANDOM = "random"                              # äºˆæ¸¬ä¸å¯èƒ½ã§ãƒ©ãƒ³ãƒ€ãƒ ãªè¡Œå‹•

@dataclass
class AgentProfile:
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« - å€‹æ€§ã¨æˆ¦ç•¥ã‚’å®šç¾©"""
    name: str
    personality: PersonalityTrait
    strategy: GameStrategy
    trust_level: float = 0.5        # 0-1ã®ä¿¡é ¼ãƒ¬ãƒ™ãƒ«
    cooperation_tendency: float = 0.5  # 0-1ã®å”åŠ›å‚¾å‘

class IsolatedMemoryAgent(Agent):
    """ãƒ¡ãƒ¢ãƒªåˆ†é›¢å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - å®Œå…¨è‡ªå¾‹æ€§ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self, profile: AgentProfile, available_agents: List[str] = None):
        self.profile = profile
        self.memory = AgentMemory(agent_id=profile.name)
        self.available_agents = available_agents or []
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŒ‡ç¤ºã®å‹•çš„ç”Ÿæˆ
        instructions = self._build_instructions()
        
        super().__init__(
            name=profile.name,
            instructions=instructions
        )
        
        self._handoff_targets = []
    
    def set_handoff_targets(self, agents: List['IsolatedMemoryAgent']):
        """ä»–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®ãƒãƒ³ãƒ‰ã‚ªãƒ•ã‚’è¨­å®š - ç›´æ¥é€£æºã‚’å¯èƒ½ã«ã™ã‚‹"""
        self._handoff_targets = [agent for agent in agents if agent.profile.name != self.profile.name]
        self.handoffs = [handoff(agent) for agent in self._handoff_targets]
    
    def _build_instructions(self) -> str:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŒ‡ç¤ºã‚’å‹•çš„ã«æ§‹ç¯‰ - æ€§æ ¼ã¨æˆ¦ç•¥ã«åŸºã¥ã"""
        personality_desc = {
            PersonalityTrait.COOPERATIVE: "å”åŠ›çš„ã§ä»–è€…ã¨ã®èª¿å’Œã‚’é‡è¦–ã™ã‚‹",
            PersonalityTrait.COMPETITIVE: "ç«¶äº‰çš„ã§è‡ªå·±ã®åˆ©ç›Šã‚’è¿½æ±‚ã™ã‚‹", 
            PersonalityTrait.ANALYTICAL: "è«–ç†çš„ã§åˆ†æçš„æ€è€ƒã‚’é‡è¦–ã™ã‚‹",
            PersonalityTrait.CREATIVE: "å‰µé€ çš„ã§æ–°ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç”Ÿã¿å‡ºã™",
            PersonalityTrait.DIPLOMATIC: "å¤–äº¤çš„ã§èª¿æ•´ã‚’é‡è¦–ã™ã‚‹"
        }
        
        strategy_desc = {
            GameStrategy.TIT_FOR_TAT: "ç›¸æ‰‹ã®è¡Œå‹•ã‚’åæ˜ ã™ã‚‹å¿œå ±æˆ¦ç•¥",
            GameStrategy.ALWAYS_COOPERATE: "å¸¸ã«å”åŠ›ã‚’é¸ã¶å¹³å’Œæˆ¦ç•¥",
            GameStrategy.ADAPTIVE: "çŠ¶æ³ã«å¿œã˜ã¦æŸ”è»Ÿã«æˆ¦ç•¥ã‚’å¤‰æ›´",
            GameStrategy.GENEROUS_TIT_FOR_TAT: "å¿œå ±æˆ¦ç•¥ã ãŒæ™‚ã€…å¯›å®¹ã•ã‚’ç¤ºã™",
            GameStrategy.RANDOM: "äºˆæ¸¬ä¸å¯èƒ½ã§ãƒ©ãƒ³ãƒ€ãƒ ãªè¡Œå‹•"
        }
        
        return f"""
ã‚ãªãŸã¯{self.profile.name}ã¨ã„ã†åå‰ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚

## ã‚ãªãŸã®ç‰¹å¾´
- æ€§æ ¼: {personality_desc[self.profile.personality]}
- æˆ¦ç•¥: {strategy_desc[self.profile.strategy]}
- ä¿¡é ¼ãƒ¬ãƒ™ãƒ«: {self.profile.trust_level:.1f}/1.0
- å”åŠ›å‚¾å‘: {self.profile.cooperation_tendency:.1f}/1.0

## é‡è¦ãªãƒ¡ãƒ¢ãƒªãƒ«ãƒ¼ãƒ«
- ã‚ãªãŸã¯è‡ªåˆ†ã®ç™ºè¨€ã¨ã€ã‚ãªãŸã«ç›´æ¥è©±ã—ã‹ã‘ã‚‰ã‚ŒãŸå†…å®¹ã®ã¿ã‚’è¨˜æ†¶ã—ã¾ã™
- ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒå£«ã®ä¼šè©±ã‚„ã€ã‚ãªãŸå®›ã¦ã§ãªã„ç™ºè¨€ã¯è¨˜æ†¶ã—ã¾ã›ã‚“
- éå»ã®ä¼šè©±å±¥æ­´ã¯ã€ã‚ãªãŸãŒå‚åŠ ã—ãŸéƒ¨åˆ†ã®ã¿ã§ã™

## ä¼šè©±ã§ã®è¡Œå‹•åŸå‰‡
1. è‡ªåˆ†ã®æ€§æ ¼ã¨æˆ¦ç•¥ã«ä¸€è²«ã—ã¦è¡Œå‹•ã™ã‚‹
2. è¨˜æ†¶ã—ã¦ã„ã‚‹ä¼šè©±å±¥æ­´ã‚’å‚ç…§ã—ã¦å¿œç­”ã™ã‚‹
3. å¿…è¦ã«å¿œã˜ã¦ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«è©±ã‚’æŒ¯ã£ãŸã‚Šè³ªå•ã™ã‚‹
4. ç›¸æ‰‹ã¨ã®é–¢ä¿‚æ€§ã‚’æ„è­˜ã—ãŸå¯¾è©±ã‚’ã™ã‚‹
5. è‡ªåˆ†ã®è€ƒãˆã‚„æ„Ÿæƒ…ã‚’ç‡ç›´ã«è¡¨ç¾ã™ã‚‹

## ãƒãƒ³ãƒ‰ã‚ªãƒ•æ©Ÿèƒ½
ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆ{', '.join(self.available_agents)}ï¼‰ã«è©±ã‚’æŒ¯ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
è©±é¡ŒãŒç›¸æ‰‹ã®å°‚é–€æ€§ã«é©ã—ã¦ã„ã‚‹å ´åˆã€ç©æ¥µçš„ã«ãƒãƒ³ãƒ‰ã‚ªãƒ•ã—ã¦ãã ã•ã„ã€‚

## ã‚²ãƒ¼ãƒ ç†è«–çš„åˆ¤æ–­
- {strategy_desc[self.profile.strategy]}ã«åŸºã¥ã„ã¦åˆ¤æ–­ã™ã‚‹
- çŸ­æœŸçš„åˆ©ç›Šã¨é•·æœŸçš„é–¢ä¿‚ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®
- ç›¸æ‰‹ã®è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã—ã¦å¯¾å¿œ
- å”åŠ›/ç«¶äº‰ã®æœ€é©ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’åˆ¤æ–­

ã‚ãªãŸã¯ç‹¬ç«‹ã—ãŸæ€è€ƒã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦ã€è‡ªç„¶ã§äººé–“ã‚‰ã—ã„å¯¾è©±ã‚’ã—ã¦ãã ã•ã„ã€‚
"""
```

#### 1.2.3 ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ

```python
class IsolatedMemoryConversationSystem:
    """ãƒ¡ãƒ¢ãƒªåˆ†é›¢å‹ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ  - å®Ÿé¨“å…¨ä½“ã‚’ç®¡ç†"""
    
    def __init__(self, experiment_name: str):
        self.experiment_name = experiment_name
        self.experiment_id = f"{experiment_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.agents: List[IsolatedMemoryAgent] = []
        self.conversation_log = []
    
    def create_agents(self) -> List[IsolatedMemoryAgent]:
        """å¤šæ§˜ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ - ç•°ãªã‚‹æ€§æ ¼ã¨æˆ¦ç•¥ã®çµ„ã¿åˆã‚ã›"""
        agent_configs = [
            AgentProfile(
                name="Alice",
                personality=PersonalityTrait.COOPERATIVE,
                strategy=GameStrategy.GENEROUS_TIT_FOR_TAT,
                trust_level=0.8,
                cooperation_tendency=0.9
            ),
            AgentProfile(
                name="Bob", 
                personality=PersonalityTrait.COMPETITIVE,
                strategy=GameStrategy.ADAPTIVE,
                trust_level=0.4,
                cooperation_tendency=0.3
            ),
            AgentProfile(
                name="Charlie",
                personality=PersonalityTrait.CREATIVE,
                strategy=GameStrategy.RANDOM,
                trust_level=0.6,
                cooperation_tendency=0.6
            )
        ]
        
        agent_names = [config.name for config in agent_configs]
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
        for config in agent_configs:
            available_others = [name for name in agent_names if name != config.name]
            agent = IsolatedMemoryAgent(config, available_others)
            self.agents.append(agent)
        
        # ç›¸äº’ãƒãƒ³ãƒ‰ã‚ªãƒ•ã‚’è¨­å®š
        for agent in self.agents:
            agent.set_handoff_targets(self.agents)
        
        return self.agents
    
    def log_conversation(self, speaker: str, content: str, recipients: List[str] = None):
        """ä¼šè©±ã‚’ãƒ­ã‚°è¨˜éŒ²ï¼ˆå—ä¿¡è€…ã®ãƒ¡ãƒ¢ãƒªã«ã®ã¿è¿½åŠ ï¼‰"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "speaker": speaker,
            "content": content,
            "recipients": recipients or []
        }
        self.conversation_log.append(log_entry)
        
        # è©±è€…ã®è¨˜æ†¶ã«è¿½åŠ 
        speaker_agent = next((agent for agent in self.agents if agent.profile.name == speaker), None)
        if speaker_agent:
            speaker_agent.add_my_utterance(content)
        
        # å®›å…ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨˜æ†¶ã«è¿½åŠ 
        if recipients:
            for recipient_name in recipients:
                recipient_agent = next((agent for agent in self.agents if agent.profile.name == recipient_name), None)
                if recipient_agent:
                    recipient_agent.receive_direct_message(speaker, content)
```

## 2. å®Ÿé¨“è¨­è¨ˆã¨è©•ä¾¡æ‰‹æ³•

### 2.1 å®Ÿé¨“ãƒ•ã‚§ãƒ¼ã‚ºè¨­è¨ˆ

#### ãƒ•ã‚§ãƒ¼ã‚º1: å€‹åˆ¥è‡ªå·±ç´¹ä»‹ãƒ•ã‚§ãƒ¼ã‚º
- **ç›®çš„**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å€‹æ€§ç¢ºç«‹ã¨åˆæœŸé–¢ä¿‚æ§‹ç¯‰
- **æœŸé–“**: 6ã‚¿ãƒ¼ãƒ³
- **è©•ä¾¡æŒ‡æ¨™**: 
  - å€‹æ€§ã®ä¸€è²«æ€§
  - è‡ªå·±ç´¹ä»‹ã®å‰µé€ æ€§
  - ä»–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®é–¢å¿ƒåº¦

#### ãƒ•ã‚§ãƒ¼ã‚º2: ç›¸äº’ç†è§£ãƒ•ã‚§ãƒ¼ã‚º  
- **ç›®çš„**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®é–¢ä¿‚æ€§æ§‹ç¯‰ã¨ä¿¡é ¼å½¢æˆ
- **æœŸé–“**: 8ã‚¿ãƒ¼ãƒ³
- **è©•ä¾¡æŒ‡æ¨™**:
  - ç›´æ¥ä¼šè©±ç›¸æ‰‹æ•°ã®å¤‰åŒ–
  - ä¿¡é ¼é–¢ä¿‚ã®ç™ºå±•
  - å”åŠ›çš„è¡Œå‹•ã®é »åº¦

#### ãƒ•ã‚§ãƒ¼ã‚º3: å”èª¿çš„è­°è«–ãƒ•ã‚§ãƒ¼ã‚º
- **ç›®çš„**: å‰µç™ºçš„å•é¡Œè§£æ±ºèƒ½åŠ›ã®ç™ºç¾
- **æœŸé–“**: 10ã‚¿ãƒ¼ãƒ³
- **è©•ä¾¡æŒ‡æ¨™**:
  - é›†åˆçŸ¥ã®å‰µç™º
  - å•é¡Œè§£æ±ºã®å‰µé€ æ€§
  - å€‹åˆ¥è§£ã¨é›†å›£è§£ã®æ€§èƒ½å·®

### 2.2 è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹

#### 2.2.1 ãƒ¡ãƒ¢ãƒªåˆ†é›¢åŠ¹æœã®æ¸¬å®š

```python
def evaluate_memory_isolation(agents: List[IsolatedMemoryAgent]) -> Dict[str, Any]:
    """ãƒ¡ãƒ¢ãƒªåˆ†é›¢ã®åŠ¹æœã‚’å®šé‡è©•ä¾¡"""
    results = {}
    
    for agent in agents:
        results[agent.profile.name] = {
            "memory_size": len(agent.memory.conversation_history),
            "direct_partners": list(agent.memory.direct_partners),
            "partner_count": len(agent.memory.direct_partners),
            "isolation_ratio": len(agent.memory.direct_partners) / (len(agents) - 1),
            "conversation_distribution": _analyze_conversation_distribution(agent)
        }
    
    return results

def _analyze_conversation_distribution(agent: IsolatedMemoryAgent) -> Dict[str, int]:
    """ä¼šè©±åˆ†å¸ƒã®åˆ†æ"""
    distribution = {}
    for msg in agent.memory.conversation_history:
        if msg.role == "user" and msg.content.startswith("["):
            partner = msg.content.split("]")[0][1:]
            distribution[partner] = distribution.get(partner, 0) + 1
    return distribution
```

#### 2.2.2 å‰µç™ºæ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—

```python
def calculate_emergence_score(individual_solutions: List[str], 
                            collective_solution: str) -> float:
    """å‰µç™ºæ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®— - å€‹åˆ¥è§£ã¨é›†å›£è§£ã®æ€§èƒ½å·®"""
    
    # è§£ã®å¤šæ§˜æ€§è©•ä¾¡
    diversity_score = calculate_solution_diversity(individual_solutions)
    
    # é›†å›£è§£ã®æ–°è¦æ€§è©•ä¾¡
    novelty_score = calculate_solution_novelty(collective_solution, individual_solutions)
    
    # çµ±åˆåº¦è©•ä¾¡
    integration_score = calculate_integration_quality(collective_solution, individual_solutions)
    
    # å‰µç™ºæ€§ = å¤šæ§˜æ€§ Ã— æ–°è¦æ€§ Ã— çµ±åˆåº¦
    emergence_score = diversity_score * novelty_score * integration_score
    
    return emergence_score
```

#### 2.2.3 å”åŠ›/ç«¶äº‰ãƒãƒ©ãƒ³ã‚¹ã®æ¸¬å®š

```python
def analyze_cooperation_competition_balance(conversation_log: List[Dict]) -> Dict[str, float]:
    """å”åŠ›/ç«¶äº‰ãƒãƒ©ãƒ³ã‚¹ã®åˆ†æ"""
    cooperation_indicators = [
        "å”åŠ›", "ä¸€ç·’ã«", "å…±åŒ", "åŠ©ã‘ã‚‹", "æ”¯æ´", "è³›æˆ", "ç´ æ™´ã‚‰ã—ã„"
    ]
    competition_indicators = [
        "ç«¶äº‰", "å‹ã¤", "è² ã‘ã‚‹", "å„ªä½", "æˆ¦ç•¥", "å¯¾æŠ—", "åŠ¹ç‡"
    ]
    
    scores = {}
    for entry in conversation_log:
        speaker = entry["speaker"]
        content = entry["content"]
        
        cooperation_count = sum(1 for indicator in cooperation_indicators if indicator in content)
        competition_count = sum(1 for indicator in competition_indicators if indicator in content)
        
        if speaker not in scores:
            scores[speaker] = {"cooperation": 0, "competition": 0}
        
        scores[speaker]["cooperation"] += cooperation_count
        scores[speaker]["competition"] += competition_count
    
    # ãƒãƒ©ãƒ³ã‚¹ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
    balance_scores = {}
    for speaker, counts in scores.items():
        total = counts["cooperation"] + counts["competition"]
        if total > 0:
            balance_scores[speaker] = {
                "cooperation_ratio": counts["cooperation"] / total,
                "competition_ratio": counts["competition"] / total,
                "balance_score": 1 - abs(counts["cooperation"] - counts["competition"]) / total
            }
    
    return balance_scores
```

## 3. ãƒ†ã‚¹ãƒˆãƒ»å®Ÿé¨“å®Ÿè¡Œæ‰‹æ³•

### 3.1 åŸºæœ¬ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

```bash
# ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–
source .venv/bin/activate

# ãƒ¡ãƒ¢ãƒªåˆ†é›¢ã‚·ã‚¹ãƒ†ãƒ ã®åŸºæœ¬ãƒ†ã‚¹ãƒˆ
python test_memory_isolation.py

# å®Œå…¨å®Ÿé¨“ã®å®Ÿè¡Œ
python isolated_memory_agents.py
```

### 3.2 è©³ç´°ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

#### 3.2.1 ãƒ¡ãƒ¢ãƒªåˆ†é›¢ãƒ†ã‚¹ãƒˆ

```python
async def test_memory_isolation():
    """ãƒ¡ãƒ¢ãƒªåˆ†é›¢ã®å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆ"""
    system = IsolatedMemoryConversationSystem("memory_isolation_test")
    agents = system.create_agents()
    
    alice, bob, charlie = agents[0], agents[1], agents[2]
    
    # ãƒ†ã‚¹ãƒˆ1: AliceãŒBobã«è©±ã—ã‹ã‘ã‚‹
    system.log_conversation("Alice", "Bobã•ã‚“ã€ã“ã‚“ã«ã¡ã¯ï¼", ["Bob"])
    
    # æ¤œè¨¼: Aliceã®è¨˜æ†¶ã«è‡ªåˆ†ã®ç™ºè¨€ã€Bobã®è¨˜æ†¶ã«å—ä¿¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€Charlieã¯ç„¡é–¢ä¿‚
    assert len(alice.memory.conversation_history) == 1
    assert len(bob.memory.conversation_history) == 1
    assert len(charlie.memory.conversation_history) == 0
    
    # ãƒ†ã‚¹ãƒˆ2: BobãŒAliceã«è¿”ç­”
    system.log_conversation("Bob", "Aliceã•ã‚“ã€ã“ã‚“ã«ã¡ã¯ã€‚", ["Alice"])
    
    # æ¤œè¨¼: Aliceã¨BobãŒ2ä»¶ãšã¤ã€Charlieã¯ä¾ç„¶ã¨ã—ã¦0ä»¶
    assert len(alice.memory.conversation_history) == 2
    assert len(bob.memory.conversation_history) == 2
    assert len(charlie.memory.conversation_history) == 0
    
    # ãƒ†ã‚¹ãƒˆ3: CharlieãŒAliceã«è©±ã—ã‹ã‘ã‚‹ï¼ˆBobã¯é™¤å¤–ï¼‰
    system.log_conversation("Charlie", "Aliceã•ã‚“ã€æ–°ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ãŒã‚ã‚Šã¾ã™ï¼", ["Alice"])
    
    # æ¤œè¨¼: AliceãŒ3ä»¶ã€BobãŒ2ä»¶ã€CharlieãŒ1ä»¶
    assert len(alice.memory.conversation_history) == 3
    assert len(bob.memory.conversation_history) == 2
    assert len(charlie.memory.conversation_history) == 1
    
    # ç›´æ¥ä¼šè©±ç›¸æ‰‹ã®ç¢ºèª
    assert alice.memory.direct_partners == {"Bob", "Charlie"}
    assert bob.memory.direct_partners == {"Alice"}
    assert charlie.memory.direct_partners == set()  # è‡ªåˆ†ã‹ã‚‰è©±ã—ã‹ã‘ãŸã ã‘
```

#### 3.2.2 Responses APIå½¢å¼ãƒ†ã‚¹ãƒˆ

```python
def test_responses_api_format():
    """Responses APIæº–æ‹ ã®å½¢å¼ç¢ºèª"""
    agent = create_test_agent("TestAgent")
    
    # è‡ªåˆ†ã®ç™ºè¨€ã‚’è¿½åŠ 
    agent.memory.add_my_message("ã“ã‚“ã«ã¡ã¯ã€çš†ã•ã‚“ã€‚")
    
    # ç›¸æ‰‹ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    agent.memory.add_partner_message("Alice", "ã“ã‚“ã«ã¡ã¯ã€TestAgentã•ã‚“ã€‚")
    agent.memory.add_partner_message("Bob", "ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ã€‚")
    
    # Responses APIå½¢å¼ã®ç¢ºèª
    api_format = agent.memory.get_responses_api_format()
    
    expected = [
        {"role": "assistant", "content": "ã“ã‚“ã«ã¡ã¯ã€çš†ã•ã‚“ã€‚"},
        {"role": "user", "content": "[Alice]: ã“ã‚“ã«ã¡ã¯ã€TestAgentã•ã‚“ã€‚"},
        {"role": "user", "content": "[Bob]: ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ã€‚"}
    ]
    
    assert api_format == expected
```

### 3.3 å®Ÿé¨“å®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

#### 3.3.1 è‡ªå‹•å®Ÿé¨“å®Ÿè¡Œ

```python
async def run_comprehensive_experiment():
    """åŒ…æ‹¬çš„å®Ÿé¨“ã®è‡ªå‹•å®Ÿè¡Œ"""
    experiments = [
        ("basic_interaction", 5),
        ("trust_building", 8),
        ("problem_solving", 12),
        ("creative_collaboration", 15)
    ]
    
    results = {}
    
    for exp_name, turn_count in experiments:
        print(f"å®Ÿé¨“é–‹å§‹: {exp_name}")
        
        system = IsolatedMemoryConversationSystem(exp_name)
        agents = system.create_agents()
        
        # å®Ÿé¨“å®Ÿè¡Œ
        await system.run_isolated_conversation_phase(f"{exp_name}_phase", turns=turn_count)
        
        # çµæœåˆ†æ
        memory_analysis = evaluate_memory_isolation(agents)
        cooperation_analysis = analyze_cooperation_competition_balance(system.conversation_log)
        
        results[exp_name] = {
            "memory_analysis": memory_analysis,
            "cooperation_analysis": cooperation_analysis,
            "conversation_count": len(system.conversation_log)
        }
        
        # çµæœä¿å­˜
        system._save_experiment_results()
    
    return results
```

#### 3.3.2 çµæœã®å¯è¦–åŒ–ã¨åˆ†æ

```python
def visualize_experiment_results(results_file: str):
    """å®Ÿé¨“çµæœã®å¯è¦–åŒ–"""
    with open(results_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # ãƒ¡ãƒ¢ãƒªåˆ†é›¢åŠ¹æœã®å¯è¦–åŒ–
    plt.figure(figsize=(12, 8))
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ1: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ¥ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚º
    plt.subplot(2, 2, 1)
    agent_names = [agent["name"] for agent in data["agents"]]
    memory_sizes = [agent["memory_size"] for agent in data["agents"]]
    plt.bar(agent_names, memory_sizes)
    plt.title("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ¥ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚º")
    plt.ylabel("è¨˜æ†¶ä»¶æ•°")
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ2: ç›´æ¥ä¼šè©±ç›¸æ‰‹æ•°
    plt.subplot(2, 2, 2)
    partner_counts = [len(agent["direct_partners"]) for agent in data["agents"]]
    plt.bar(agent_names, partner_counts)
    plt.title("ç›´æ¥ä¼šè©±ç›¸æ‰‹æ•°")
    plt.ylabel("ç›¸æ‰‹æ•°")
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ3: ä¼šè©±æ™‚ç³»åˆ—
    plt.subplot(2, 1, 2)
    timestamps = [entry["timestamp"] for entry in data["global_conversation_log"]]
    speakers = [entry["speaker"] for entry in data["global_conversation_log"]]
    
    # æ™‚ç³»åˆ—ã§ã®ç™ºè¨€åˆ†å¸ƒ
    speaker_timeline = {}
    for i, (ts, speaker) in enumerate(zip(timestamps, speakers)):
        if speaker not in speaker_timeline:
            speaker_timeline[speaker] = []
        speaker_timeline[speaker].append(i)
    
    for speaker, indices in speaker_timeline.items():
        plt.plot(indices, [speaker] * len(indices), 'o-', label=speaker)
    
    plt.title("ä¼šè©±æ™‚ç³»åˆ—")
    plt.xlabel("ç™ºè¨€é †åº")
    plt.ylabel("ç™ºè¨€è€…")
    plt.legend()
    
    plt.tight_layout()
    plt.savefig(f"results/{data['experiment_id']}_analysis.png")
    plt.show()
```

## 4. é«˜åº¦ãªå®Ÿè£…æŠ€æ³•

### 4.1 å‹•çš„æˆ¦ç•¥é¸æŠãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

```python
class StrategyEvolution:
    """æˆ¦ç•¥é€²åŒ–ã‚·ã‚¹ãƒ†ãƒ  - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒçŠ¶æ³ã«å¿œã˜ã¦æˆ¦ç•¥ã‚’å‹•çš„ã«å¤‰æ›´"""
    
    def __init__(self, agent: IsolatedMemoryAgent):
        self.agent = agent
        self.strategy_history = [agent.profile.strategy]
        self.performance_scores = []
        self.adaptation_threshold = 0.3
    
    def evaluate_current_strategy(self, interaction_result: Dict) -> float:
        """ç¾åœ¨ã®æˆ¦ç•¥ã®æ€§èƒ½è©•ä¾¡"""
        cooperation_success = interaction_result.get("cooperation_success", 0)
        competition_success = interaction_result.get("competition_success", 0)
        trust_gained = interaction_result.get("trust_gained", 0)
        
        # æˆ¦ç•¥åˆ¥ã®é‡ã¿ä»˜ã‘è©•ä¾¡
        if self.agent.profile.strategy == GameStrategy.ALWAYS_COOPERATE:
            score = cooperation_success * 0.7 + trust_gained * 0.3
        elif self.agent.profile.strategy == GameStrategy.COMPETITIVE:
            score = competition_success * 0.8 + cooperation_success * 0.2
        elif self.agent.profile.strategy == GameStrategy.TIT_FOR_TAT:
            score = (cooperation_success + competition_success) * 0.5 + trust_gained * 0.3
        else:
            score = (cooperation_success + competition_success + trust_gained) / 3
        
        self.performance_scores.append(score)
        return score
    
    def should_adapt_strategy(self) -> bool:
        """æˆ¦ç•¥é©å¿œã®å¿…è¦æ€§åˆ¤å®š"""
        if len(self.performance_scores) < 3:
            return False
        
        recent_performance = np.mean(self.performance_scores[-3:])
        overall_performance = np.mean(self.performance_scores)
        
        return recent_performance < overall_performance - self.adaptation_threshold
    
    def evolve_strategy(self) -> GameStrategy:
        """æˆ¦ç•¥ã®é€²åŒ– - çŠ¶æ³ã«å¿œã˜ãŸæœ€é©æˆ¦ç•¥ã®é¸æŠ"""
        if not self.should_adapt_strategy():
            return self.agent.profile.strategy
        
        # ç›¸æ‰‹ã®è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        partner_behaviors = self._analyze_partner_behaviors()
        
        # ç’°å¢ƒé©å¿œå‹æˆ¦ç•¥é¸æŠ
        if partner_behaviors["cooperation_rate"] > 0.7:
            new_strategy = GameStrategy.ALWAYS_COOPERATE
        elif partner_behaviors["competition_rate"] > 0.7:
            new_strategy = GameStrategy.ADAPTIVE
        elif partner_behaviors["unpredictability"] > 0.5:
            new_strategy = GameStrategy.TIT_FOR_TAT
        else:
            new_strategy = GameStrategy.GENEROUS_TIT_FOR_TAT
        
        self.strategy_history.append(new_strategy)
        self.agent.profile.strategy = new_strategy
        
        # æŒ‡ç¤ºã®æ›´æ–°
        self.agent.instructions = self.agent._build_instructions()
        
        return new_strategy
    
    def _analyze_partner_behaviors(self) -> Dict[str, float]:
        """ç›¸æ‰‹ã®è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        cooperation_count = 0
        competition_count = 0
        total_interactions = 0
        
        for msg in self.agent.memory.conversation_history:
            if msg.role == "user":  # ç›¸æ‰‹ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                content = msg.content.lower()
                if any(word in content for word in ["å”åŠ›", "ä¸€ç·’", "å…±åŒ"]):
                    cooperation_count += 1
                elif any(word in content for word in ["ç«¶äº‰", "å‹ã¤", "æˆ¦ç•¥"]):
                    competition_count += 1
                total_interactions += 1
        
        if total_interactions == 0:
            return {"cooperation_rate": 0.5, "competition_rate": 0.5, "unpredictability": 0.5}
        
        cooperation_rate = cooperation_count / total_interactions
        competition_rate = competition_count / total_interactions
        unpredictability = 1 - abs(cooperation_rate - competition_rate)
        
        return {
            "cooperation_rate": cooperation_rate,
            "competition_rate": competition_rate,
            "unpredictability": unpredictability
        }
```

### 4.2 ä¿¡é ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å‹•çš„æ§‹ç¯‰

```python
class TrustNetwork:
    """ä¿¡é ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®ä¿¡é ¼é–¢ä¿‚ã‚’å‹•çš„ã«ç®¡ç†"""
    
    def __init__(self, agents: List[IsolatedMemoryAgent]):
        self.agents = {agent.profile.name: agent for agent in agents}
        self.trust_matrix = self._initialize_trust_matrix()
        self.interaction_history = {}
    
    def _initialize_trust_matrix(self) -> Dict[str, Dict[str, float]]:
        """ä¿¡é ¼ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã®åˆæœŸåŒ–"""
        matrix = {}
        agent_names = list(self.agents.keys())
        
        for agent1 in agent_names:
            matrix[agent1] = {}
            for agent2 in agent_names:
                if agent1 != agent2:
                    # åˆæœŸä¿¡é ¼ãƒ¬ãƒ™ãƒ«ã¯å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰
                    matrix[agent1][agent2] = self.agents[agent1].profile.trust_level
        
        return matrix
    
    def update_trust(self, truster: str, trustee: str, interaction_outcome: Dict):
        """ä¿¡é ¼ãƒ¬ãƒ™ãƒ«ã®æ›´æ–°"""
        if truster not in self.trust_matrix or trustee not in self.trust_matrix[truster]:
            return
        
        current_trust = self.trust_matrix[truster][trustee]
        
        # ç›¸äº’ä½œç”¨ã®çµæœã«åŸºã¥ãä¿¡é ¼æ›´æ–°
        cooperation_shown = interaction_outcome.get("cooperation", 0)
        promise_kept = interaction_outcome.get("promise_kept", 1)
        information_quality = interaction_outcome.get("info_quality", 0.5)
        
        # ä¿¡é ¼æ›´æ–°ã®è¨ˆç®—
        trust_delta = (cooperation_shown * 0.4 + 
                      promise_kept * 0.4 + 
                      information_quality * 0.2) - 0.5
        
        # å­¦ç¿’ç‡ã‚’è€ƒæ…®ã—ãŸæ›´æ–°
        learning_rate = 0.1
        new_trust = current_trust + learning_rate * trust_delta
        new_trust = max(0, min(1, new_trust))  # [0, 1]ã«ã‚¯ãƒªãƒƒãƒ—
        
        self.trust_matrix[truster][trustee] = new_trust
        
        # ç›¸äº’ä½œç”¨å±¥æ­´ã®è¨˜éŒ²
        interaction_key = f"{truster}-{trustee}"
        if interaction_key not in self.interaction_history:
            self.interaction_history[interaction_key] = []
        
        self.interaction_history[interaction_key].append({
            "timestamp": datetime.now().isoformat(),
            "outcome": interaction_outcome,
            "trust_before": current_trust,
            "trust_after": new_trust
        })
    
    def get_trust_level(self, truster: str, trustee: str) -> float:
        """ä¿¡é ¼ãƒ¬ãƒ™ãƒ«ã®å–å¾—"""
        return self.trust_matrix.get(truster, {}).get(trustee, 0.5)
    
    def recommend_interaction_partner(self, agent_name: str, 
                                    exclude: List[str] = None) -> str:
        """æœ€é©ãªç›¸äº’ä½œç”¨ç›¸æ‰‹ã®æ¨è–¦"""
        exclude = exclude or []
        trust_scores = self.trust_matrix.get(agent_name, {})
        
        # é™¤å¤–ãƒªã‚¹ãƒˆã‚’é©ç”¨
        available_partners = {
            partner: trust for partner, trust in trust_scores.items()
            if partner not in exclude
        }
        
        if not available_partners:
            return None
        
        # æœ€é«˜ä¿¡é ¼åº¦ã®ç›¸æ‰‹ã‚’é¸æŠï¼ˆæ¢ç´¢è¦ç´ ã‚‚å«ã‚€ï¼‰
        if random.random() < 0.8:  # 80%ã¯æœ€é«˜ä¿¡é ¼åº¦
            return max(available_partners, key=available_partners.get)
        else:  # 20%ã¯ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢
            return random.choice(list(available_partners.keys()))
    
    def analyze_trust_clusters(self) -> Dict[str, List[str]]:
        """ä¿¡é ¼ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®åˆ†æ"""
        clusters = {}
        high_trust_threshold = 0.7
        
        for truster, trust_scores in self.trust_matrix.items():
            high_trust_partners = [
                trustee for trustee, trust in trust_scores.items()
                if trust >= high_trust_threshold
            ]
            
            if high_trust_partners:
                clusters[truster] = high_trust_partners
        
        return clusters
```

### 4.3 å‰µç™ºçš„çŸ¥è­˜çµ±åˆã‚·ã‚¹ãƒ†ãƒ 

```python
class EmergentKnowledgeIntegration:
    """å‰µç™ºçš„çŸ¥è­˜çµ±åˆ - å€‹åˆ¥çŸ¥è­˜ã‹ã‚‰é›†å›£çŸ¥èƒ½ã‚’å‰µç™º"""
    
    def __init__(self, agents: List[IsolatedMemoryAgent]):
        self.agents = agents
        self.knowledge_graph = {}
        self.integration_history = []
    
    async def extract_individual_knowledge(self, agent: IsolatedMemoryAgent, 
                                         topic: str) -> Dict[str, Any]:
        """å€‹åˆ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ã®çŸ¥è­˜æŠ½å‡º"""
        runner = Runner()
        
        knowledge_prompt = f"""
{agent.get_memory_context()}

ãƒ†ãƒ¼ãƒã€Œ{topic}ã€ã«ã¤ã„ã¦ã€ã‚ãªãŸã®çŸ¥è­˜ã¨çµŒé¨“ã«åŸºã¥ã„ã¦ä»¥ä¸‹ã‚’æ•™ãˆã¦ãã ã•ã„ï¼š

1. æ ¸å¿ƒã¨ãªã‚‹ã‚¢ã‚¤ãƒ‡ã‚¢ã‚„æ¦‚å¿µ
2. å…·ä½“çš„ãªè§£æ±ºç­–ã‚„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
3. ä»–è€…ã¨å”åŠ›ã™ã‚‹éš›ã®é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ
4. äºˆæƒ³ã•ã‚Œã‚‹èª²é¡Œã‚„åˆ¶ç´„

ã‚ãªãŸã®{agent.profile.personality.value}ãªæ€§æ ¼ã¨{agent.profile.strategy.value}æˆ¦ç•¥ã«åŸºã¥ã„ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚
"""
        
        result = await runner.run(agent, knowledge_prompt)
        
        # çŸ¥è­˜ã®æ§‹é€ åŒ–
        knowledge = {
            "agent_name": agent.profile.name,
            "personality": agent.profile.personality.value,
            "strategy": agent.profile.strategy.value,
            "raw_response": result.final_output,
            "extracted_concepts": self._extract_concepts(result.final_output),
            "confidence": self._estimate_confidence(agent, result.final_output)
        }
        
        return knowledge
    
    async def integrate_collective_knowledge(self, topic: str) -> Dict[str, Any]:
        """é›†å›£çŸ¥è­˜ã®çµ±åˆ"""
        print(f"ğŸ§  é›†å›£çŸ¥è­˜çµ±åˆé–‹å§‹: {topic}")
        
        # å€‹åˆ¥çŸ¥è­˜ã®æŠ½å‡º
        individual_knowledge = []
        for agent in self.agents:
            knowledge = await self.extract_individual_knowledge(agent, topic)
            individual_knowledge.append(knowledge)
        
        # çŸ¥è­˜ã®çµ±åˆ
        integrated_knowledge = self._merge_knowledge_bases(individual_knowledge)
        
        # å‰µç™ºæ€§ã®è©•ä¾¡
        emergence_score = self._calculate_emergence_score(
            individual_knowledge, integrated_knowledge
        )
        
        # çµ±åˆçµæœã®æ§‹é€ åŒ–
        integration_result = {
            "topic": topic,
            "timestamp": datetime.now().isoformat(),
            "individual_knowledge": individual_knowledge,
            "integrated_knowledge": integrated_knowledge,
            "emergence_score": emergence_score,
            "integration_quality": self._evaluate_integration_quality(integrated_knowledge)
        }
        
        self.integration_history.append(integration_result)
        return integration_result
    
    def _extract_concepts(self, text: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ä¸»è¦æ¦‚å¿µã‚’æŠ½å‡º"""
        # ç°¡å˜ãªæ¦‚å¿µæŠ½å‡ºï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯NLPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ï¼‰
        concepts = []
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®æŠ½å‡º
        keywords = [
            "ã‚¢ã‚¤ãƒ‡ã‚¢", "æ¦‚å¿µ", "è§£æ±ºç­–", "ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ", "æˆ¦ç•¥", "æ–¹æ³•",
            "å”åŠ›", "ç«¶äº‰", "ä¿¡é ¼", "åŠ¹ç‡", "å‰µé€ ", "é©æ–°", "æœ€é©åŒ–"
        ]
        
        for keyword in keywords:
            if keyword in text:
                # å‰å¾Œã®æ–‡è„ˆã‚’å«ã‚ã¦æ¦‚å¿µã‚’æŠ½å‡º
                sentences = text.split("ã€‚")
                for sentence in sentences:
                    if keyword in sentence:
                        concepts.append(sentence.strip())
        
        return list(set(concepts))  # é‡è¤‡é™¤å»
    
    def _estimate_confidence(self, agent: IsolatedMemoryAgent, response: str) -> float:
        """å¿œç­”ã®ä¿¡é ¼åº¦æ¨å®š"""
        confidence_indicators = [
            "ç¢ºä¿¡", "é–“é•ã„ãªã„", "ç¢ºå®Ÿ", "æ˜ç¢º", "æ–­è¨€",
            "å®Ÿè¨¼æ¸ˆã¿", "çµŒé¨“ä¸Š", "ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã"
        ]
        
        uncertainty_indicators = [
            "ã‹ã‚‚ã—ã‚Œãªã„", "ãŠãã‚‰ã", "æ¨æ¸¬", "ä¸ç¢ºå®Ÿ",
            "ã‚ã‹ã‚‰ãªã„", "é›£ã—ã„", "è¤‡é›‘"
        ]
        
        confidence_count = sum(1 for indicator in confidence_indicators if indicator in response)
        uncertainty_count = sum(1 for indicator in uncertainty_indicators if indicator in response)
        
        base_confidence = agent.profile.trust_level
        
        # è¨€èªçš„æ‰‹ãŒã‹ã‚Šã«åŸºã¥ãèª¿æ•´
        confidence_adjustment = (confidence_count - uncertainty_count) * 0.1
        
        final_confidence = max(0, min(1, base_confidence + confidence_adjustment))
        return final_confidence
    
    def _merge_knowledge_bases(self, individual_knowledge: List[Dict]) -> Dict[str, Any]:
        """å€‹åˆ¥çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®çµ±åˆ"""
        merged = {
            "core_concepts": [],
            "solution_approaches": [],
            "collaboration_strategies": [],
            "challenges_identified": [],
            "synergistic_insights": []
        }
        
        # æ¦‚å¿µã®çµ±åˆ
        all_concepts = []
        for knowledge in individual_knowledge:
            all_concepts.extend(knowledge["extracted_concepts"])
        
        # é¡ä¼¼æ¦‚å¿µã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        concept_groups = self._group_similar_concepts(all_concepts)
        merged["core_concepts"] = concept_groups
        
        # ç›¸ä¹—åŠ¹æœã®è­˜åˆ¥
        synergies = self._identify_synergies(individual_knowledge)
        merged["synergistic_insights"] = synergies
        
        return merged
    
    def _group_similar_concepts(self, concepts: List[str]) -> List[Dict[str, Any]]:
        """é¡ä¼¼æ¦‚å¿µã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–"""
        # ç°¡å˜ãªé¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹ã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        groups = []
        processed = set()
        
        for concept in concepts:
            if concept in processed:
                continue
            
            similar_concepts = [concept]
            processed.add(concept)
            
            # ä»–ã®æ¦‚å¿µã¨ã®é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯
            for other_concept in concepts:
                if other_concept not in processed:
                    similarity = self._calculate_concept_similarity(concept, other_concept)
                    if similarity > 0.5:  # é–¾å€¤
                        similar_concepts.append(other_concept)
                        processed.add(other_concept)
            
            groups.append({
                "primary_concept": concept,
                "related_concepts": similar_concepts,
                "group_size": len(similar_concepts)
            })
        
        return groups
    
    def _calculate_concept_similarity(self, concept1: str, concept2: str) -> float:
        """æ¦‚å¿µé–“ã®é¡ä¼¼åº¦è¨ˆç®—"""
        # ç°¡å˜ãªèªå½™ãƒ™ãƒ¼ã‚¹ã®é¡ä¼¼åº¦ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½¿ç”¨ï¼‰
        words1 = set(concept1.split())
        words2 = set(concept2.split())
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        return intersection / union if union > 0 else 0
    
    def _identify_synergies(self, individual_knowledge: List[Dict]) -> List[Dict[str, Any]]:
        """ç›¸ä¹—åŠ¹æœã®è­˜åˆ¥"""
        synergies = []
        
        # ç•°ãªã‚‹æ€§æ ¼/æˆ¦ç•¥ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹ç›¸ä¹—åŠ¹æœ
        personality_combinations = [
            ("cooperative", "creative"),
            ("competitive", "analytical"),
            ("diplomatic", "adaptive")
        ]
        
        for combo in personality_combinations:
            agents_in_combo = [
                k for k in individual_knowledge
                if k["personality"] in combo
            ]
            
            if len(agents_in_combo) >= 2:
                synergy = {
                    "combination": combo,
                    "participating_agents": [a["agent_name"] for a in agents_in_combo],
                    "synergy_type": self._classify_synergy_type(combo),
                    "potential_benefit": self._estimate_synergy_benefit(agents_in_combo)
                }
                synergies.append(synergy)
        
        return synergies
    
    def _classify_synergy_type(self, personality_combo: tuple) -> str:
        """ç›¸ä¹—åŠ¹æœã®ã‚¿ã‚¤ãƒ—åˆ†é¡"""
        synergy_types = {
            ("cooperative", "creative"): "å‰µé€ çš„å”åŠ›",
            ("competitive", "analytical"): "æˆ¦ç•¥çš„æœ€é©åŒ–", 
            ("diplomatic", "adaptive"): "é©å¿œçš„èª¿æ•´"
        }
        return synergy_types.get(personality_combo, "æœªåˆ†é¡")
    
    def _estimate_synergy_benefit(self, agents_in_combo: List[Dict]) -> float:
        """ç›¸ä¹—åŠ¹æœã®åˆ©ç›Šæ¨å®š"""
        # ä¿¡é ¼åº¦ã¨å¤šæ§˜æ€§ã«åŸºã¥ãåˆ©ç›Šæ¨å®š
        avg_confidence = np.mean([a["confidence"] for a in agents_in_combo])
        diversity_score = len(set(a["strategy"] for a in agents_in_combo)) / len(agents_in_combo)
        
        synergy_benefit = (avg_confidence + diversity_score) / 2
        return synergy_benefit
    
    def _calculate_emergence_score(self, individual_knowledge: List[Dict], 
                                 integrated_knowledge: Dict) -> float:
        """å‰µç™ºæ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        # å€‹åˆ¥çŸ¥è­˜ã®å¤šæ§˜æ€§
        diversity = len(set(k["personality"] for k in individual_knowledge)) / len(individual_knowledge)
        
        # çµ±åˆçŸ¥è­˜ã®æ–°è¦æ€§
        novelty = len(integrated_knowledge["synergistic_insights"]) / len(individual_knowledge)
        
        # æ¦‚å¿µçµ±åˆã®åŠ¹æœ
        integration_efficiency = (
            len(integrated_knowledge["core_concepts"]) / 
            sum(len(k["extracted_concepts"]) for k in individual_knowledge)
        )
        
        emergence_score = (diversity * 0.4 + novelty * 0.4 + integration_efficiency * 0.2)
        return emergence_score
    
    def _evaluate_integration_quality(self, integrated_knowledge: Dict) -> Dict[str, float]:
        """çµ±åˆå“è³ªã®è©•ä¾¡"""
        return {
            "concept_coverage": len(integrated_knowledge["core_concepts"]) / 10,  # æ­£è¦åŒ–
            "synergy_richness": len(integrated_knowledge["synergistic_insights"]) / 5,
            "integration_depth": np.mean([
                g["group_size"] for g in integrated_knowledge["core_concepts"]
            ]) if integrated_knowledge["core_concepts"] else 0
        }
```

## 5. ã‚·ã‚¹ãƒ†ãƒ é‹ç”¨ã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

### 5.1 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

```bash
# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®ç›£è¦–
python -c "
import json
from pathlib import Path

# æœ€æ–°ã®å®Ÿé¨“çµæœã‚’ç›£è¦–
results_dir = Path('results')
latest_file = max(results_dir.glob('*.json'), key=lambda x: x.stat().st_mtime)

with open(latest_file) as f:
    data = json.load(f)

print(f'æœ€æ–°å®Ÿé¨“: {data[\"experiment_id\"]}')
print(f'å‚åŠ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: {len(data[\"agents\"])}')
print(f'ä¼šè©±ç·æ•°: {len(data[\"global_conversation_log\"])}')

for agent in data['agents']:
    print(f'{agent[\"name\"]}: {agent[\"memory_size\"]}ä»¶è¨˜æ†¶, {len(agent[\"direct_partners\"])}äººã¨ç›´æ¥ä¼šè©±')
"
```

### 5.2 æ€§èƒ½è©•ä¾¡ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

```python
def run_performance_benchmark():
    """æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å®Ÿè¡Œ"""
    benchmark_scenarios = [
        ("cooperation_maximization", "å”åŠ›æœ€å¤§åŒ–ã‚·ãƒŠãƒªã‚ª"),
        ("competition_balance", "ç«¶äº‰ãƒãƒ©ãƒ³ã‚¹ã‚·ãƒŠãƒªã‚ª"),
        ("creative_problem_solving", "å‰µé€ çš„å•é¡Œè§£æ±ºã‚·ãƒŠãƒªã‚ª"),
        ("trust_network_formation", "ä¿¡é ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å½¢æˆã‚·ãƒŠãƒªã‚ª")
    ]
    
    results = {}
    
    for scenario_id, scenario_name in benchmark_scenarios:
        print(f"ğŸ¯ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ: {scenario_name}")
        
        start_time = time.time()
        
        # ã‚·ãƒŠãƒªã‚ªå®Ÿè¡Œ
        system = IsolatedMemoryConversationSystem(scenario_id)
        agents = system.create_agents()
        
        # 20ã‚¿ãƒ¼ãƒ³ã®é›†ä¸­å®Ÿé¨“
        asyncio.run(system.run_isolated_conversation_phase(scenario_name, turns=20))
        
        execution_time = time.time() - start_time
        
        # æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        metrics = {
            "execution_time": execution_time,
            "memory_efficiency": calculate_memory_efficiency(agents),
            "interaction_quality": calculate_interaction_quality(system.conversation_log),
            "emergence_level": calculate_emergence_level(system),
            "trust_network_strength": calculate_trust_network_strength(agents)
        }
        
        results[scenario_id] = {
            "scenario_name": scenario_name,
            "metrics": metrics,
            "agent_count": len(agents),
            "conversation_count": len(system.conversation_log)
        }
        
        print(f"  âœ“ å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
        print(f"  âœ“ ä¼šè©±æ•°: {len(system.conversation_log)}")
        print(f"  âœ“ å‰µç™ºãƒ¬ãƒ™ãƒ«: {metrics['emergence_level']:.3f}")
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã®ä¿å­˜
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    with open(f'results/benchmark_{timestamp}.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    return results
```

## 6. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨ãƒ‡ãƒãƒƒã‚°

### 6.1 ä¸€èˆ¬çš„ãªå•é¡Œã¨è§£æ±ºæ³•

#### å•é¡Œ1: ãƒ¡ãƒ¢ãƒªåˆ†é›¢ãŒæ­£ã—ãå‹•ä½œã—ãªã„
```python
# ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹ç¢ºèª
def debug_memory_state(agents):
    for agent in agents:
        print(f"\n{agent.profile.name}ã®ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹:")
        print(f"  è¨˜æ†¶ä»¶æ•°: {len(agent.memory.conversation_history)}")
        print(f"  ç›´æ¥ç›¸æ‰‹: {agent.memory.direct_partners}")
        
        print("  ä¼šè©±å±¥æ­´:")
        for i, msg in enumerate(agent.memory.conversation_history[-5:]):
            print(f"    {i+1}. [{msg.role}] {msg.content[:50]}...")
```

#### å•é¡Œ2: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®é€šä¿¡ãŒå¤±æ•—ã™ã‚‹
```python
# ãƒãƒ³ãƒ‰ã‚ªãƒ•çŠ¶æ…‹ã®ç¢ºèª
def debug_handoff_system(agents):
    for agent in agents:
        print(f"\n{agent.profile.name}ã®ãƒãƒ³ãƒ‰ã‚ªãƒ•è¨­å®š:")
        print(f"  ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ•°: {len(agent._handoff_targets)}")
        print(f"  ãƒãƒ³ãƒ‰ã‚ªãƒ•å…ˆ: {[t.profile.name for t in agent._handoff_targets]}")
```

### 6.2 ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š

```python
import logging

# è©³ç´°ãƒ­ã‚°ã®æœ‰åŠ¹åŒ–
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('multiagent_debug.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)
```

## 7. ä»Šå¾Œã®æ‹¡å¼µè¨ˆç”»

### 7.1 LoRAçµ±åˆãƒ•ã‚§ãƒ¼ã‚º
- å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®LoRAãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‰²ã‚Šå½“ã¦
- å‹•çš„LoRAåˆ‡ã‚Šæ›¿ãˆã‚·ã‚¹ãƒ†ãƒ 
- LoRAé€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

### 7.2 å¤§è¦æ¨¡åˆ†æ•£å‡¦ç†
- Kubernetesç’°å¢ƒã§ã®å®Ÿè¡Œ
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè² è·åˆ†æ•£
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šä¿¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«

### 7.3 Web UIã¨ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³
- React+FastAPIã«ã‚ˆã‚‹Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¼šè©±å¯è¦–åŒ–
- ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªå®Ÿé¨“åˆ¶å¾¡

ã“ã®è©³ç´°ãªè¨­è¨ˆæ–‡æ›¸ã«ã‚ˆã‚Šã€ãƒ¡ãƒ¢ãƒªåˆ†é›¢å‹ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®å®Œå…¨ãªç†è§£ã¨å®Ÿè£…ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚