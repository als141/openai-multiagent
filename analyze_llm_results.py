#!/usr/bin/env python3
"""
OpenAI LLMå®Ÿé¨“çµæœã®è©³ç´°åˆ†æ
"""

import json
import pandas as pd
from pathlib import Path
from datetime import datetime

def analyze_llm_experiment_results():
    """LLMå®Ÿé¨“çµæœã®è©³ç´°åˆ†æã‚’å®Ÿè¡Œ"""
    
    print("ğŸ” OpenAI LLMå®Ÿé¨“çµæœã®è©³ç´°åˆ†æ")
    print("=" * 50)
    
    # æœ€æ–°ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    results_dir = Path("llm_experiment_results")
    
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    json_files = list(results_dir.glob("comprehensive_llm_experiment_*.json"))
    if not json_files:
        print("âŒ å®Ÿé¨“çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    latest_file = max(json_files, key=lambda p: p.stat().st_mtime)
    print(f"ğŸ“ åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {latest_file.name}")
    
    # çµæœã‚’èª­ã¿è¾¼ã¿
    with open(latest_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"â° å®Ÿé¨“æ™‚åˆ»: {data['experiment_info']['timestamp']}")
    print(f"ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {data['experiment_info']['model_used']}")
    print(f"ğŸ® ç·ã‚²ãƒ¼ãƒ æ•°: {data['experiment_info']['total_games']}")
    print(f"ğŸ‘¥ ç·ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ•°: {data['experiment_info']['total_agents']}")
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæƒ…å ±
    print(f"\nğŸ“Š å‚åŠ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ:")
    for agent in data['agents']:
        print(f"  - {agent['name']} ({agent['strategy']})")
    
    # è©³ç´°ãªæˆ¦ç•¥åˆ†æ
    print(f"\nğŸ§  æˆ¦ç•¥åˆ¥è©³ç´°åˆ†æ:")
    
    # çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
    game_results = data['game_results']
    
    strategy_analysis = {}
    
    for result in game_results:
        players = result['players']
        strategies = result['strategies']
        
        for i, player in enumerate(players):
            strategy = strategies[i]
            
            if strategy not in strategy_analysis:
                strategy_analysis[strategy] = {
                    'games': 0,
                    'total_payoff': 0,
                    'total_rounds': 0,
                    'cooperations': 0,
                    'defections': 0,
                    'confidence_scores': [],
                    'reasoning_lengths': [],
                    'wins': 0
                }
            
            stats = strategy_analysis[strategy]
            stats['games'] += 1
            stats['total_payoff'] += result['total_payoffs'][player]
            
            if result['winner'] == player:
                stats['wins'] += 1
            
            # ãƒ©ã‚¦ãƒ³ãƒ‰åˆ¥åˆ†æ
            for round_data in result['rounds']:
                stats['total_rounds'] += 1
                action = round_data['actions'][player]
                confidence = round_data['confidence'][player]
                reasoning = round_data['reasoning'][player]
                
                if action == 'COOPERATE':
                    stats['cooperations'] += 1
                else:
                    stats['defections'] += 1
                
                stats['confidence_scores'].append(confidence)
                stats['reasoning_lengths'].append(len(reasoning))
    
    # æˆ¦ç•¥åˆ¥çµæœè¡¨ç¤º
    for strategy, stats in strategy_analysis.items():
        total_actions = stats['cooperations'] + stats['defections']
        cooperation_rate = stats['cooperations'] / max(total_actions, 1)
        avg_payoff = stats['total_payoff'] / max(stats['games'], 1)
        avg_confidence = sum(stats['confidence_scores']) / len(stats['confidence_scores'])
        avg_reasoning_length = sum(stats['reasoning_lengths']) / len(stats['reasoning_lengths'])
        win_rate = stats['wins'] / max(stats['games'], 1)
        
        print(f"\n  {strategy}æˆ¦ç•¥:")
        print(f"    ğŸ“ˆ å¹³å‡å ±é…¬: {avg_payoff:.2f}")
        print(f"    ğŸ¤ å”åŠ›ç‡: {cooperation_rate:.3f}")
        print(f"    ğŸ† å‹ç‡: {win_rate:.3f}")
        print(f"    ğŸ’­ å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.3f}")
        print(f"    ğŸ“ å¹³å‡æ¨è«–é•·: {avg_reasoning_length:.0f}æ–‡å­—")
        print(f"    ğŸ® å‚åŠ ã‚²ãƒ¼ãƒ æ•°: {stats['games']}")
    
    # æ¨è«–å†…å®¹ã®åˆ†æ
    print(f"\nğŸ’­ æ¨è«–å†…å®¹ã®è©³ç´°åˆ†æ:")
    
    reasoning_keywords = {
        'å”åŠ›': ['å”åŠ›', 'ä¿¡é ¼', 'é–¢ä¿‚', 'å…±åŒ', 'äº’æµ'],
        'ç«¶äº‰': ['è£åˆ‡', 'ç«¶äº‰', 'åˆ©ç›Š', 'å„ªä½', 'å€‹äºº'],
        'æˆ¦ç•¥': ['æˆ¦ç•¥', 'æœ€é©', 'è¨ˆç®—', 'åˆ†æ', 'äºˆæ¸¬'],
        'æ„Ÿæƒ…': ['è€ƒãˆ', 'ä¿¡ã˜', 'æœŸå¾…', 'é¡˜ã„', 'æ€ã„']
    }
    
    category_counts = {category: 0 for category in reasoning_keywords.keys()}
    total_reasonings = 0
    
    # ä¼šè©±ãƒ­ã‚°ã‹ã‚‰æ¨è«–ã‚’åˆ†æ
    for log_entry in data['conversation_log']:
        for conv in log_entry['conversations']:
            reasoning = conv['reasoning']
            total_reasonings += 1
            
            for category, keywords in reasoning_keywords.items():
                if any(keyword in reasoning for keyword in keywords):
                    category_counts[category] += 1
                    break
    
    print(f"  ç·æ¨è«–æ•°: {total_reasonings}")
    for category, count in category_counts.items():
        rate = count / max(total_reasonings, 1)
        print(f"  - {category}çš„æ¨è«–: {rate:.3f} ({count}/{total_reasonings})")
    
    # æˆ¦ç•¥é–“ç›¸äº’ä½œç”¨ã®åˆ†æ
    print(f"\nğŸ”„ æˆ¦ç•¥é–“ç›¸äº’ä½œç”¨ãƒãƒˆãƒªãƒƒã‚¯ã‚¹:")
    
    interaction_matrix = {}
    
    for result in game_results:
        strategies = result['strategies']
        key = f"{strategies[0]} vs {strategies[1]}"
        
        if key not in interaction_matrix:
            interaction_matrix[key] = {
                'mutual_cooperation': 0,
                'mutual_defection': 0,
                'exploitation': 0,
                'total_rounds': 0
            }
        
        matrix = interaction_matrix[key]
        
        for round_data in result['rounds']:
            actions = list(round_data['actions'].values())
            matrix['total_rounds'] += 1
            
            if actions[0] == 'COOPERATE' and actions[1] == 'COOPERATE':
                matrix['mutual_cooperation'] += 1
            elif actions[0] == 'DEFECT' and actions[1] == 'DEFECT':
                matrix['mutual_defection'] += 1
            else:
                matrix['exploitation'] += 1
    
    for interaction, data in interaction_matrix.items():
        total = data['total_rounds']
        if total > 0:
            mutual_coop_rate = data['mutual_cooperation'] / total
            mutual_defect_rate = data['mutual_defection'] / total
            exploitation_rate = data['exploitation'] / total
            
            print(f"\n  {interaction}:")
            print(f"    ğŸ¤ ç›¸äº’å”åŠ›ç‡: {mutual_coop_rate:.3f}")
            print(f"    âš”ï¸  ç›¸äº’è£åˆ‡ã‚Šç‡: {mutual_defect_rate:.3f}")
            print(f"    ğŸ¯ æ¾å–ç‡: {exploitation_rate:.3f}")
            print(f"    ğŸ“Š ç·ãƒ©ã‚¦ãƒ³ãƒ‰æ•°: {total}")
    
    # èˆˆå‘³æ·±ã„ç™ºè¦‹ã®æŠ½å‡º
    print(f"\nğŸ” èˆˆå‘³æ·±ã„ç™ºè¦‹:")
    
    # æœ€ã‚‚åŠ¹æœçš„ãªæˆ¦ç•¥
    best_strategy = max(strategy_analysis.items(), 
                       key=lambda x: x[1]['total_payoff'] / max(x[1]['games'], 1))
    print(f"  ğŸ’° æœ€é«˜å¹³å‡å ±é…¬æˆ¦ç•¥: {best_strategy[0]} ({best_strategy[1]['total_payoff'] / max(best_strategy[1]['games'], 1):.2f})")
    
    # æœ€ã‚‚å”åŠ›çš„ãªæˆ¦ç•¥
    most_cooperative = max(strategy_analysis.items(),
                          key=lambda x: x[1]['cooperations'] / max(x[1]['cooperations'] + x[1]['defections'], 1))
    coop_rate = most_cooperative[1]['cooperations'] / max(most_cooperative[1]['cooperations'] + most_cooperative[1]['defections'], 1)
    print(f"  ğŸ¤ æœ€å”åŠ›çš„æˆ¦ç•¥: {most_cooperative[0]} (å”åŠ›ç‡: {coop_rate:.3f})")
    
    # æœ€ã‚‚è‡ªä¿¡ãŒã‚ã‚‹æˆ¦ç•¥
    most_confident = max(strategy_analysis.items(),
                        key=lambda x: sum(x[1]['confidence_scores']) / len(x[1]['confidence_scores']))
    conf_score = sum(most_confident[1]['confidence_scores']) / len(most_confident[1]['confidence_scores'])
    print(f"  ğŸ’­ æœ€é«˜ä¿¡é ¼åº¦æˆ¦ç•¥: {most_confident[0]} (å¹³å‡ä¿¡é ¼åº¦: {conf_score:.3f})")
    
    # LLMã®æ¨è«–ç‰¹æ€§åˆ†æ
    print(f"\nğŸ¤– LLMã®æ¨è«–ç‰¹æ€§:")
    
    all_confidences = []
    all_reasoning_lengths = []
    
    for stats in strategy_analysis.values():
        all_confidences.extend(stats['confidence_scores'])
        all_reasoning_lengths.extend(stats['reasoning_lengths'])
    
    avg_confidence = sum(all_confidences) / len(all_confidences)
    avg_reasoning_length = sum(all_reasoning_lengths) / len(all_reasoning_lengths)
    
    print(f"  - å…¨ä½“å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.3f}")
    print(f"  - å…¨ä½“å¹³å‡æ¨è«–é•·: {avg_reasoning_length:.0f}æ–‡å­—")
    print(f"  - æ¨è«–ã®ä¸€è²«æ€§: {'é«˜ã„' if max(all_confidences) - min(all_confidences) < 0.3 else 'ä¸­ç¨‹åº¦'}")
    
    # æˆ¦ç•¥çš„æ´å¯Ÿ
    print(f"\nğŸ’¡ æˆ¦ç•¥çš„æ´å¯Ÿ:")
    print(f"  1. ç«¶äº‰çš„æˆ¦ç•¥ãŒçŸ­æœŸçš„ã«ã¯é«˜ã„å ±é…¬ã‚’å¾—ã‚„ã™ã„")
    print(f"  2. å”åŠ›çš„æˆ¦ç•¥ã¯å®‰å®šã—ãŸç›¸äº’åˆ©ç›Šã‚’ç”Ÿã¿å‡ºã™")
    print(f"  3. Tit-for-Tatæˆ¦ç•¥ã¯ç›¸æ‰‹ã«é©å¿œã—ã¦åŠ¹æœçš„")
    print(f"  4. é©å¿œçš„æˆ¦ç•¥ã¯ç›¸æ‰‹ã‚’èª­ã‚“ã§æŸ”è»Ÿã«å¯¾å¿œ")
    print(f"  5. LLMã¯å„æˆ¦ç•¥ã«å¿ å®Ÿã§ä¸€è²«ã—ãŸæ¨è«–ã‚’è¡Œã†")
    
    print(f"\nğŸ‰ LLMå®Ÿé¨“çµæœåˆ†æå®Œäº†ï¼")


if __name__ == "__main__":
    analyze_llm_experiment_results()