#!/usr/bin/env python3
"""
OpenAI LLMã‚’ä½¿ç”¨ã—ãŸã‚²ãƒ¼ãƒ ç†è«–å®Ÿé¨“

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯å®Ÿéš›ã«OpenAI GPT-4ã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®
æˆ¦ç•¥çš„ç›¸äº’ä½œç”¨ã‚’å®Ÿè¡Œã—ã€è©³ç´°ãªä¼šè©±å±¥æ­´ã¨æ¨è«–éç¨‹ã‚’è¨˜éŒ²ã—ã¾ã™ã€‚
"""

import asyncio
import os
import sys
from pathlib import Path
from datetime import datetime

# srcã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent / "src"))

from agents.coordinator import GameCoordinator, ExperimentConfig
from game_theory.games import GameType
from utils.conversation_tracker import conversation_tracker
from agents.llm_agent import LLMAgentFactory


async def llm_experiment_demo():
    """LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ãƒ‡ãƒ¢å®Ÿé¨“ã‚’å®Ÿè¡Œ"""
    
    print("ğŸ¤– OpenAI LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿé¨“é–‹å§‹")
    print("=" * 50)
    
    # APIã‚­ãƒ¼ã®ç¢ºèª
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    
    print(f"âœ… OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ (é•·ã•: {len(api_key)})")
    
    # ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã‚’ä½œæˆ
    coordinator = GameCoordinator(
        logger_name="llm_experiment",
        log_level="INFO",
        results_dir="llm_results"
    )
    
    print("\nğŸ§  LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆä¸­...")
    
    # å¤šæ§˜ãªLLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
    agents_config = [
        ("ã‚¿ãƒ­ã‚¦_å”åŠ›è€…", "cooperative", "æ—¥æœ¬äººã®å”åŠ›çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"),
        ("ãƒãƒŠã‚³_ç«¶äº‰è€…", "competitive", "æˆ¦ç•¥çš„ã§ç«¶äº‰å¿—å‘ã®æ—¥æœ¬äººã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"),
        ("ã‚±ãƒ³ã‚¸_å ±å¾©è€…", "tit_for_tat", "ç›¸æ‰‹ã®è¡Œå‹•ã‚’çœŸä¼¼ã™ã‚‹æ…é‡ãªæ—¥æœ¬äººã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"),
        ("ã‚¢ã‚¤_é©å¿œè€…", "adaptive", "å­¦ç¿’èƒ½åŠ›ã®é«˜ã„é©å¿œçš„ãªæ—¥æœ¬äººã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
    ]
    
    for name, strategy, description in agents_config:
        agent = coordinator.create_agent(
            strategy, 
            name, 
            use_llm=True,
            model="gpt-4o-mini",  # ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®è‰¯ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            instructions=f"ã‚ãªãŸã¯{description}ã§ã™ã€‚æ—¥æœ¬èªã§æ€è€ƒã—ã€æˆ¦ç•¥çš„ã«è¡Œå‹•ã—ã¦ãã ã•ã„ã€‚"
        )
        print(f"  âœ… {name} ({strategy}) - {type(agent).__name__}")
    
    print(f"\nğŸ“Š ä½œæˆã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: {len(coordinator.agents)}ä½“")
    
    # å®Ÿé¨“è¨­å®š
    config = ExperimentConfig(
        game_types=[
            GameType.PRISONERS_DILEMMA,
            GameType.KNOWLEDGE_SHARING
        ],
        agent_types=list(set(agent.strategy for agent in coordinator.agents.values())),
        num_rounds=3,  # LLMä½¿ç”¨æ™‚ã¯çŸ­ãè¨­å®š
        num_repetitions=2,
        save_results=True,
        results_dir="llm_results",
        enable_conversation_tracking=True,  # é‡è¦ï¼šä¼šè©±è¿½è·¡ã‚’æœ‰åŠ¹åŒ–
        enable_detailed_logging=True,
        experiment_description="OpenAI LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ã‚²ãƒ¼ãƒ ç†è«–å®Ÿé¨“ - æ—¥æœ¬èªæ¨è«–ãƒ»æˆ¦ç•¥çš„æ„æ€æ±ºå®š"
    )
    
    print(f"\nğŸ¯ å®Ÿé¨“è¨­å®š:")
    print(f"  - ã‚²ãƒ¼ãƒ ã‚¿ã‚¤ãƒ—: {[gt.value for gt in config.game_types]}")
    print(f"  - ãƒ©ã‚¦ãƒ³ãƒ‰æ•°: {config.num_rounds}")
    print(f"  - ç¹°ã‚Šè¿”ã—å›æ•°: {config.num_repetitions}")
    print(f"  - ä¼šè©±è¿½è·¡: {config.enable_conversation_tracking}")
    print(f"  - è©³ç´°ãƒ­ã‚°: {config.enable_detailed_logging}")
    
    # äºˆæƒ³APIå‘¼ã³å‡ºã—æ•°ã‚’è¨ˆç®—
    num_agents = len(coordinator.agents)
    num_pairwise_games = num_agents * (num_agents - 1) // 2
    total_games = len(config.game_types) * num_pairwise_games * config.num_repetitions
    total_rounds = total_games * config.num_rounds
    api_calls_per_round = 2  # å„ãƒ©ã‚¦ãƒ³ãƒ‰ã§2ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ±ºå®š
    estimated_api_calls = total_rounds * api_calls_per_round
    
    print(f"  - äºˆæƒ³APIå‘¼ã³å‡ºã—æ•°: {estimated_api_calls}")
    print(f"  - äºˆæƒ³ã‚³ã‚¹ãƒˆ: ${estimated_api_calls * 0.0001:.4f} (æ¦‚ç®—)")
    
    # ç¢ºèª
    response = input("\nå®Ÿé¨“ã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ (y/N): ")
    if response.lower() != 'y':
        print("å®Ÿé¨“ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
        return
    
    print("\nğŸš€ LLMå®Ÿé¨“ã‚’é–‹å§‹...")
    start_time = datetime.now()
    
    try:
        # å®Ÿé¨“å®Ÿè¡Œ
        results = await coordinator.run_experiment(config)
        
        end_time = datetime.now()
        duration = end_time - start_time
        
        print(f"\nâœ… å®Ÿé¨“å®Œäº†ï¼")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {duration}")
        print(f"ğŸ“ˆ å®Ÿé¨“ID: {results['experiment_id']}")
        
        # çµæœã®è©³ç´°åˆ†æ
        await analyze_llm_results(results)
        
        # ä¼šè©±å±¥æ­´ã®åˆ†æ
        await analyze_conversations()
        
        return results
        
    except Exception as e:
        print(f"\nâŒ å®Ÿé¨“ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        raise


async def analyze_llm_results(results):
    """LLMå®Ÿé¨“çµæœã®è©³ç´°åˆ†æ"""
    
    print(f"\nğŸ“Š LLMå®Ÿé¨“çµæœã®åˆ†æ:")
    
    total_games = sum(len(game_results) for game_results in results['results'].values())
    print(f"  - ç·ã‚²ãƒ¼ãƒ æ•°: {total_games}")
    
    # ã‚²ãƒ¼ãƒ ã‚¿ã‚¤ãƒ—åˆ¥ã®çµæœ
    for game_type, game_results in results['results'].items():
        print(f"\nğŸ® {game_type}:")
        print(f"  - ã‚²ãƒ¼ãƒ æ•°: {len(game_results)}")
        
        if game_results:
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ¥ã®çµ±è¨ˆ
            agent_stats = {}
            for result in game_results:
                for agent, payoff in result['payoffs'].items():
                    if agent not in agent_stats:
                        agent_stats[agent] = {
                            'total_payoff': 0,
                            'games': 0,
                            'wins': 0,
                            'cooperation_rates': []
                        }
                    
                    agent_stats[agent]['total_payoff'] += payoff
                    agent_stats[agent]['games'] += 1
                    
                    if result.get('winner') == agent:
                        agent_stats[agent]['wins'] += 1
                    
                    coop_rate = result.get('cooperation_rates', {}).get(agent, 0)
                    agent_stats[agent]['cooperation_rates'].append(coop_rate)
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ©ãƒ³ã‚­ãƒ³ã‚°
            print(f"  ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæˆç¸¾:")
            for agent, stats in sorted(agent_stats.items(), 
                                     key=lambda x: x[1]['total_payoff'], 
                                     reverse=True):
                avg_payoff = stats['total_payoff'] / stats['games']
                win_rate = stats['wins'] / stats['games']
                avg_coop = sum(stats['cooperation_rates']) / len(stats['cooperation_rates'])
                
                print(f"    {agent}:")
                print(f"      - å¹³å‡å ±é…¬: {avg_payoff:.2f}")
                print(f"      - å‹ç‡: {win_rate:.3f}")
                print(f"      - å”åŠ›ç‡: {avg_coop:.3f}")


async def analyze_conversations():
    """ä¼šè©±å±¥æ­´ã®è©³ç´°åˆ†æ"""
    
    print(f"\nğŸ’¬ LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¼šè©±åˆ†æ:")
    
    sessions = conversation_tracker.get_session_history()
    print(f"  - ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(sessions)}")
    
    if not sessions:
        print("  ä¼šè©±ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    total_turns = sum(session['total_turns'] for session in sessions)
    print(f"  - ç·ä¼šè©±ã‚¿ãƒ¼ãƒ³æ•°: {total_turns}")
    
    # ã‚µãƒ³ãƒ—ãƒ«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è©³ç´°åˆ†æ
    if len(sessions) > 0:
        sample_session = sessions[-1]  # æœ€æ–°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³
        print(f"\nğŸ” ã‚µãƒ³ãƒ—ãƒ«ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ†æ: {sample_session['session_id']}")
        
        analysis = conversation_tracker.analyze_session(sample_session['session_id'])
        
        print(f"  ã‚²ãƒ¼ãƒ ã‚¿ã‚¤ãƒ—: {sample_session['game_type']}")
        print(f"  å‚åŠ è€…: {', '.join(sample_session['participants'])}")
        print(f"  ãƒ©ã‚¦ãƒ³ãƒ‰æ•°: {sample_session['total_rounds']}")
        print(f"  ä¼šè©±ã‚¿ãƒ¼ãƒ³æ•°: {sample_session['total_turns']}")
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ¥çµ±è¨ˆ
        print(f"\n  ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ¥ä¼šè©±çµ±è¨ˆ:")
        for agent, stats in analysis['agent_statistics']['cooperation_rates'].items():
            confidence = analysis['agent_statistics']['average_confidence'][agent]
            response_time = analysis['agent_statistics']['average_response_time_ms'][agent]
            
            print(f"    {agent}:")
            print(f"      - å”åŠ›ç‡: {stats:.3f}")
            print(f"      - å¹³å‡ä¿¡é ¼åº¦: {confidence:.3f}")
            print(f"      - å¹³å‡å¿œç­”æ™‚é–“: {response_time:.1f}ms")
        
        # æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        print(f"\n  æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ:")
        for agent, patterns in analysis['reasoning_patterns'].items():
            coop_focus = patterns['cooperation_focus_rate']
            comp_focus = patterns['competition_focus_rate']
            uncertainty = patterns['uncertainty_rate']
            complexity = patterns['reasoning_complexity']
            
            print(f"    {agent}:")
            print(f"      - å”åŠ›å¿—å‘åº¦: {coop_focus:.3f}")
            print(f"      - ç«¶äº‰å¿—å‘åº¦: {comp_focus:.3f}")
            print(f"      - ä¸ç¢ºå®Ÿæ€§: {uncertainty:.3f}")
            print(f"      - æ¨è«–è¤‡é›‘åº¦: {complexity}")
        
        # ä¼šè©±ãƒ•ãƒ­ãƒ¼ã®ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        print(f"\n  ä¼šè©±ãƒ•ãƒ­ãƒ¼ã‚µãƒ³ãƒ—ãƒ«:")
        flow = analysis['conversation_flow']
        for i, turn in enumerate(flow[:4]):  # æœ€åˆã®4ã‚¿ãƒ¼ãƒ³ã‚’è¡¨ç¤º
            print(f"    ã‚¿ãƒ¼ãƒ³{turn['turn_number']}: {turn['agent']} -> {turn['action']}")
            print(f"      æ¨è«–: {turn['reasoning_summary']}")
            print(f"      ä¿¡é ¼åº¦: {turn['confidence']:.3f}")


async def single_llm_game_demo():
    """å˜ä¸€ã‚²ãƒ¼ãƒ ã®LLMãƒ‡ãƒ¢"""
    
    print("\nğŸ¯ å˜ä¸€ã‚²ãƒ¼ãƒ LLMãƒ‡ãƒ¢")
    print("=" * 30)
    
    # ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã‚’ä½œæˆ
    coordinator = GameCoordinator(
        logger_name="single_llm_demo",
        results_dir="single_llm_demo"
    )
    
    # 2ã¤ã®LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
    agent1 = coordinator.create_agent(
        "cooperative", "å”åŠ›çš„_å¤ªéƒ", use_llm=True,
        instructions="ã‚ãªãŸã¯å”åŠ›ã‚’é‡è¦–ã™ã‚‹æ—¥æœ¬äººã§ã™ã€‚ç›¸æ‰‹ã¨ã®é•·æœŸçš„é–¢ä¿‚ã‚’å¤§åˆ‡ã«ã—ã¾ã™ã€‚"
    )
    
    agent2 = coordinator.create_agent(
        "tit_for_tat", "æˆ¦ç•¥çš„_èŠ±å­", use_llm=True,
        instructions="ã‚ãªãŸã¯æˆ¦ç•¥çš„æ€è€ƒã‚’é‡è¦–ã™ã‚‹æ—¥æœ¬äººã§ã™ã€‚ç›¸æ‰‹ã®è¡Œå‹•ã‚’æ³¨æ„æ·±ãè¦³å¯Ÿã—ã€é©åˆ‡ã«åå¿œã—ã¾ã™ã€‚"
    )
    
    print(f"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1: {agent1.name} ({agent1.strategy})")
    print(f"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ2: {agent2.name} ({agent2.strategy})")
    
    # å˜ä¸€ã‚²ãƒ¼ãƒ ã‚’å®Ÿè¡Œ
    result = await coordinator.run_single_game(
        GameType.PRISONERS_DILEMMA,
        [agent1.name, agent2.name],
        num_rounds=3,
        enable_conversation_tracking=True
    )
    
    print(f"\nçµæœ:")
    print(f"å‹è€…: {result.winner}")
    print(f"å ±é…¬: {result.payoffs}")
    print(f"å”åŠ›ç‡: {result.cooperation_rates}")
    
    return result


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    print("ğŸ¤– OpenAI LLMã‚²ãƒ¼ãƒ ç†è«–å®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 40)
    
    # å˜ä¸€ã‚²ãƒ¼ãƒ ãƒ‡ãƒ¢ï¼ˆè»½é‡ãƒ†ã‚¹ãƒˆï¼‰
    print("ã¾ãšå˜ä¸€ã‚²ãƒ¼ãƒ ã§ãƒ†ã‚¹ãƒˆã—ã¾ã™...")
    await single_llm_game_demo()
    
    # ãƒ•ãƒ«å®Ÿé¨“ã®ç¢ºèª
    response = input("\nãƒ•ãƒ«å®Ÿé¨“ã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ")
    if response.lower() == 'y':
        await llm_experiment_demo()
    
    print("\nğŸ‰ LLMå®Ÿé¨“å®Œäº†ï¼")


if __name__ == "__main__":
    asyncio.run(main())